{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e461ed1c-c557-4695-ba8d-1d9035dd7759",
   "metadata": {},
   "source": [
    "# LLMs vs. TextWorld\n",
    "This notebook tests and proves the hypothesis that modern, off-the-shelf LLMs — even non-reasoning models such as GPT-4o — can achieve high win rates in TextWorld when given a detailed prompt and a walkthrough of an example game, without any task-specific training. Games are generated via `tw-cooking --recipe 3 --take 2 --go 12 --open --cook --cut --drop`, essentially configuring them for maximum difficulty. Of the four models tested, the best-performing is Llama-3.1-405B-Instruct-FP8, which won at 96 out of 100 seeds on its first attempt, and all 100 within two attempts. Difficulty navigating the map is the most common source of failure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QluFBqjcyA0n",
   "metadata": {
    "id": "QluFBqjcyA0n"
   },
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XS8ZHsjCWTGC",
   "metadata": {
    "id": "XS8ZHsjCWTGC"
   },
   "source": [
    "This section sets up a portable notebook environment which can run on a local kernel or on Google Colab. It pip-installs dependencies, sets up a place to store experimental results, and sets up a mechanism for accessing API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "_nKkQ_BHUYSj",
   "metadata": {
    "id": "_nKkQ_BHUYSj"
   },
   "outputs": [],
   "source": [
    "import jupyter_core, os, os.path, sys, sysconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xa1ZDHAntwOO",
   "metadata": {
    "id": "Xa1ZDHAntwOO"
   },
   "source": [
    "First we need to pip-install some prerequisites and locate the `tw-make` binary. `tw-make` generates the TextWorld games that we'll be testing against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e62d7ff-746d-4052-a9e8-42a2c52d9fe3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e62d7ff-746d-4052-a9e8-42a2c52d9fe3",
    "outputId": "1c653d3d-e41d-4bd7-babb-64fdc5381a2f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textworld in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (1.6.2)\n",
      "Requirement already satisfied: openai in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (1.63.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from textworld) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.17.1 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from textworld) (4.67.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from textworld) (1.17.1)\n",
      "Requirement already satisfied: networkx>=2 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from textworld) (3.4.2)\n",
      "Requirement already satisfied: more_itertools in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from textworld) (10.6.0)\n",
      "Requirement already satisfied: tatsu==5.8.3 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from textworld) (5.8.3)\n",
      "Requirement already satisfied: hashids>=1.2.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from textworld) (1.3.1)\n",
      "Requirement already satisfied: jericho>=3.3.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from textworld) (3.3.0)\n",
      "Requirement already satisfied: mementos>=1.3.1 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from textworld) (1.3.1)\n",
      "Requirement already satisfied: termcolor in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from textworld) (2.5.0)\n",
      "Requirement already satisfied: prompt_toolkit in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from textworld) (3.0.50)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: pycparser in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from cffi>=1.0.0->textworld) (2.22)\n",
      "Requirement already satisfied: certifi in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: spacy>=2.1.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from jericho>=3.3.0->textworld) (3.8.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: wcwidth in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from prompt_toolkit->textworld) (0.2.13)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (0.15.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (2.32.3)\n",
      "Requirement already satisfied: jinja2 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (3.1.5)\n",
      "Requirement already satisfied: setuptools in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (2.3.0)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy>=2.1.0->jericho>=3.3.0->textworld) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy>=2.1.0->jericho>=3.3.0->textworld) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from jinja2->spacy>=2.1.0->jericho>=3.3.0->textworld) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (2.19.1)\n",
      "Requirement already satisfied: wrapt in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/home/dfranke/.local/share/pipx/venvs/jupyterlab/bin/python -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install textworld openai\n",
    "\n",
    "TW_MAKE_BIN = os.path.join(sysconfig.get_path(\"scripts\"), \"tw-make\")\n",
    "assert os.path.exists(TW_MAKE_BIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r_IgLxj7uoHw",
   "metadata": {
    "id": "r_IgLxj7uoHw"
   },
   "source": [
    "Now we define `WORK_DIR`, where we'll store generated games and experimental results. We'll use a Google Drive if we're running in Colab, otherwise use the Jupyter data directory. You might want to customize this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "xJeBXu_VvC5D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJeBXu_VvC5D",
    "outputId": "e1ce8f5f-34ab-4b4e-c80f-29694decd298"
   },
   "outputs": [],
   "source": [
    "USE_GOOGLE_DRIVE : bool = True\n",
    "OFFLINE_WORK_DIR : str = os.path.join(\n",
    "    jupyter_core.paths.jupyter_data_dir(),\n",
    "\"textworld\")\n",
    "ONLINE_WORK_DIR : str = \"/content/drive/MyDrive/textworld\"\n",
    "\n",
    "if USE_GOOGLE_DRIVE:\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount(\"/content/drive\", force_remount=True)\n",
    "        WORK_DIR : str = ONLINE_WORK_DIR\n",
    "    except ImportError:\n",
    "        WORK_DIR = OFFLINE_WORK_DIR\n",
    "else:\n",
    "    WORK_DIR = OFFLINE_WORK_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZMpYJtUvt6-m",
   "metadata": {
    "id": "ZMpYJtUvt6-m"
   },
   "source": [
    "This next cell defines a function for accessing API keys. It supports getting them from Colab's secret store or from environment variables. You may need to modify it if you want to access them through some other mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0gQxwL5mtD7D",
   "metadata": {
    "id": "0gQxwL5mtD7D"
   },
   "outputs": [],
   "source": [
    "def get_api_key(service : str) -> str:\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "\n",
    "        secret = userdata.get(service)\n",
    "        if secret is not None:\n",
    "            return secret\n",
    "    except ImportError:\n",
    "        pass\n",
    "    secret = os.environ.get(service.upper())\n",
    "    if secret is None:\n",
    "        warnings.warn(\n",
    "            \"Failed to retrieve API key for {}. Set it in Colab secrets \"\n",
    "            \"or via the {} environment variable.\".format(\n",
    "                service, service.upper()\n",
    "            )\n",
    "        )\n",
    "    return secret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MwPSIoM_SrUs",
   "metadata": {
    "id": "MwPSIoM_SrUs"
   },
   "source": [
    "## Apparatus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xdh7UNzFYtSD",
   "metadata": {
    "id": "xdh7UNzFYtSD"
   },
   "source": [
    "In this section we'll develop the apparatus for generating TextWorld games, interfacing LLMs to them, and recording their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "yt_6BdzC1v6c",
   "metadata": {
    "id": "yt_6BdzC1v6c"
   },
   "outputs": [],
   "source": [
    "import copy, hashlib, itertools, json, jupyter_core, multiprocessing, openai, os, \\\n",
    "    os.path, random, re, subprocess, tarfile, tempfile, textworld, textworld.gym, \\\n",
    "    time, urllib, warnings\n",
    "from typing import Any, Dict, Iterable, List, Literal, Mapping, NotRequired, Optional, \\\n",
    "    Tuple, TypedDict, Union, cast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2gkXEfnuY-XP",
   "metadata": {
    "id": "2gkXEfnuY-XP"
   },
   "source": [
    "We support generating games using `tw-make` or downloading pre-generated games from the web. We'll generate all the games that we'll be testing the LLMs against, but for the first experiment we'll download an example game from the TextWorld website and use that to generate a walkthrough to include in the LLMs' prompt.\n",
    "\n",
    "The constructor for `GeneratedGame` takes a seed and a list of arguments and invokes `tw-make` accordingly. It stores the game under `$WORK_DIR/games` and names the file after a SHA-256 hash of the arguments that were given. If the file already exists, it skips regenerating the game.\n",
    "\n",
    "The constructor for `FetchedGame` takes a URL for the game's `.z8` file and optionally a second one for the associated `.json` file. The `.z8` file contains the game itself and the `.json` file contains some metadata that the TextWorld gym can optionally use to report more detailed information about the state of a game. The fetched game is stored in a temporary directory which is cleaned up when the `FetchedGame` object is GCed.\n",
    "\n",
    "Both classes provide a `.path` attribute which evaluates to a string giving the path of the `.z8` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "jcaxCV3RVJup",
   "metadata": {
    "id": "jcaxCV3RVJup"
   },
   "outputs": [],
   "source": [
    "class GeneratedGame:\n",
    "    def __init__(\n",
    "        self,\n",
    "        seed : int,\n",
    "        tw_make_args : List[str],\n",
    "        tw_make_bin : str = TW_MAKE_BIN,\n",
    "        game_dir : str = os.path.join(WORK_DIR, \"games\"),\n",
    "    ):\n",
    "        game_file = \"{}-{}.z8\".format(\n",
    "            hashlib.sha256(\"\\0\".join(tw_make_args).encode(\"utf-8\")).hexdigest(),\n",
    "            seed\n",
    "        )\n",
    "        os.makedirs(game_dir, exist_ok=True)\n",
    "        self.path : str = os.path.join(game_dir, game_file)\n",
    "        if os.path.exists(self.path):\n",
    "            self.have_info = os.path.exists(\n",
    "                os.path.splitext(self.path)[0] + \".json\"\n",
    "            )\n",
    "            return\n",
    "        args = [tw_make_bin] + tw_make_args + \\\n",
    "            [\"--output\", self.path, \"--seed\", str(seed)]\n",
    "        subprocess.run(args).check_returncode()\n",
    "        self.have_info = True\n",
    "\n",
    "class FetchedGame:\n",
    "    def __init__(\n",
    "        self,\n",
    "        z8_url: str,\n",
    "        json_url: Optional[str] = None\n",
    "    ):\n",
    "        self._tempdir = tempfile.TemporaryDirectory()\n",
    "        self.path = os.path.join(self._tempdir.name, \"game.z8\")\n",
    "        z8_request = urllib.request.urlopen(z8_url)\n",
    "        with open(self.path, \"wb\") as f:\n",
    "            f.write(z8_request.read())\n",
    "        if json_url is not None:\n",
    "            json_request = urllib.request.urlopen(json_url)\n",
    "            with open(os.path.join(self._tempdir.name, \"game.json\"), \"wb\") as f:\n",
    "                f.write(json_request.read())\n",
    "            self.have_info = True\n",
    "        else:\n",
    "            self.have_info = False\n",
    "\n",
    "Game = Union[GeneratedGame, FetchedGame]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fYpvDAIrcb_h",
   "metadata": {
    "id": "fYpvDAIrcb_h"
   },
   "source": [
    "`GameRunner` is a wrapper around a TextWorld gym environment which strips the parenthetical thoughts that we'll be prompting LLMs to include in their output, and also incorporates workarounds for a couple TextWorld bugs. A `GameRunner` can be constructed from an existing `GeneratedGame` or `FetchedGame` object, or from arguments to the constructors for the same. Its `reset` method starts a new game and returns a string containing the game's opening text. Its `step` method takes player input as a string, and returns a tuple `(obs, outcome)`. `obs` is a string containing the game's response to the input. `outcome` is one of \"won\", \"lost\", \"quit\" or \"turnmax\" if the game has ended, indicating respectively that the player won the game, lost, quit out, or hit the configured turn limit. An outcome of `False` indicates that the game is still in progress. If the game's .json metadata is not available, then it is not possible to determine game status and `outcome` will be `None`.\n",
    "\n",
    "The `step` method will throw a `GameRunnerException` if the player input contains no command, multiple commands, or imbalanced parentheses. The rejection of multiple commands is a workaround for https://github.com/microsoft/TextWorld/issues/366. These exceptions are intended to be caught, and their messages are formatted as to be provided directly to the LLM agent as a developer prompt instructing the agent to correct its output. They also include an `old_message` attribute with a legacy wording which is less effective at getting the agent to correct its behavior, but can be used when reproducing the first of the two experiments in this notebook.\n",
    "\n",
    "The `_clean_obs` method is a workaround for another, minor TextWorld bug, wherein the observation that the gym returns includes, without delimiters, text that the Z-machine intended to place into an overhead status bar. This is ugly and not useful so we strip it away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "RV7YEpOzzXuq",
   "metadata": {
    "id": "RV7YEpOzzXuq"
   },
   "outputs": [],
   "source": [
    "class GameRunnerException(Exception):\n",
    "    def __init__(self, message):\n",
    "        super().__init__(message)\n",
    "        self.old_message = message\n",
    "\n",
    "class ImbalancedParensException(GameRunnerException):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            message=\"I couldn't interpret your last message because it \"\n",
    "                \"contained imbalanced parentheses. Please try again.\"\n",
    "        )\n",
    "\n",
    "class NoCommandException(GameRunnerException):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            message=\"Your last message contained only a parenthetical, so there was \"\n",
    "                \"no command to execute. Please try again, placing your thoughts \"\n",
    "                \"inside parenthesis and the game command outside them.\"\n",
    "        )\n",
    "        self.old_message = \\\n",
    "            \"Your last message contained nothing except a parenthetical,\\n\" \\\n",
    "            \"so it couldn't be provided to the game. Try again. If you've \\n\" \\\n",
    "            \"completely given up, just say QUIT.\\n\\n>\"\n",
    "\n",
    "class MultipleCommandException(GameRunnerException):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            message=\"Your last message appeared to contain a series of multiple \"\n",
    "            \"commands. The game doesn't support this. Please try again, issuing \"\n",
    "            \"just one command at a time.\"\n",
    "        )\n",
    "        self.old_message = \\\n",
    "            \"Your last message looks like you may have tried to issue\\n\" \\\n",
    "            \"multiple commands at once. The game doesn't support this.\\n\" \\\n",
    "            \"Try again, one command at a time.\"\n",
    "\n",
    "GameRunnerOutcome = Literal[None, False, \"won\", \"lost\", \"quit\", \"turnmax\"]\n",
    "\n",
    "class GameRunner:\n",
    "    def _clean_obs(self, obs: str) -> str:\n",
    "        return re.sub(r\">[^>]*$\", \"> \", obs)\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            game: Optional[Game] = None,\n",
    "            seed: Optional[int] = None,\n",
    "            tw_make_args: Optional[List[str]] = None,\n",
    "            tw_make_bin: str = TW_MAKE_BIN,\n",
    "            z8_url: Optional[str] = None,\n",
    "            json_url: Optional[str] = None,\n",
    "            max_turns : int = 100\n",
    "        ):\n",
    "            if game is not None:\n",
    "                self.game : Game = game\n",
    "                if seed is not None:\n",
    "                    raise ValueError(\"Cannot specify both game and seed\")\n",
    "                if z8_url is not None:\n",
    "                    raise ValueError(\"Cannot specify both game and z8_url\")\n",
    "            elif seed is not None:\n",
    "                if tw_make_args is None:\n",
    "                    raise ValueError(\"Must specify tw_make_args if specifying seed\")\n",
    "                self.game = GeneratedGame(seed, tw_make_args, tw_make_bin)\n",
    "                if z8_url is not None:\n",
    "                    raise ValueError(\"Cannot specify both seed and z8_url\")\n",
    "            elif z8_url is not None:\n",
    "                self.game = FetchedGame(z8_url, json_url)\n",
    "            else:\n",
    "                raise ValueError(\"Must specify either game, seed, or z8_url\")\n",
    "\n",
    "            if self.game.have_info:\n",
    "                request_infos = textworld.core.EnvInfos(lost=True, won=True)\n",
    "            else:\n",
    "                request_infos = None\n",
    "\n",
    "            self._env_id = textworld.gym.register_game(\n",
    "                self.game.path,\n",
    "                request_infos=request_infos,\n",
    "                name=self.game.path,\n",
    "                max_episode_steps=max_turns,\n",
    "            )\n",
    "            self._env = textworld.gym.make(self._env_id)\n",
    "\n",
    "    def reset(self) -> str:\n",
    "        obs, _ = self._env.reset()\n",
    "        return self._clean_obs(obs)\n",
    "\n",
    "    def step(self, action) -> Tuple[str, GameRunnerOutcome]:\n",
    "        # Strip balanced, innermost parentheticals until none remain\n",
    "        while True:\n",
    "            new_action = re.sub(r\"[(][^()]*[)]\", \"\", action)\n",
    "            if new_action == action:\n",
    "                break\n",
    "            action = new_action\n",
    "        if \"(\" in action or \")\" in action:\n",
    "            raise ImbalancedParensException()\n",
    "        action = action.lstrip().rstrip(\". \\r\\n\")\n",
    "        if action == \"\":\n",
    "            raise NoCommandException()\n",
    "        if '.' in action or ',' in action or ';' in action or '\\n' in action or \\\n",
    "                re.search(r\"\\b(THEN|AND)\\b\", action, re.IGNORECASE):\n",
    "            raise MultipleCommandException()\n",
    "        if re.match(r\"(QUIT|RESTART)\\b\", action, re.IGNORECASE):\n",
    "            self._env.close()\n",
    "            return (\"\", \"quit\")\n",
    "        obs, _, done, infos = self._env.step(action)\n",
    "        obs = self._clean_obs(obs)\n",
    "\n",
    "        if done:\n",
    "            if infos.get('won', False):\n",
    "                return (obs, 'won')\n",
    "            elif infos.get('lost', False):\n",
    "                return (obs, 'lost')\n",
    "            else:\n",
    "                return (obs, 'turnmax')\n",
    "        elif self.game.have_info:\n",
    "            return (obs, False)\n",
    "        else:\n",
    "            return (obs, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1GPGCmbQh2cA",
   "metadata": {
    "id": "1GPGCmbQh2cA"
   },
   "source": [
    "`AgentRunner` wraps the interaction with the LLM agent. It is constructed from an OpenAI client object and a `ProcessedModelSpec`, which is a dictionary type. Most of the entries in a `ProcessedModelSpec` are passed as keyword arguments to the OpenAI `chat.completions.create` API endpoint. It also takes a `developer_role` key which can specify a different role to substitute for \"developer\" when sending a developer prompt. This can be used to change the deveolper prompt into a user prompt in order to support models such as `o1-mini` which don't support developer prompts.\n",
    "\n",
    "`AgentRunner` provides various `append` methods for adding onto the chat transcript, and a `run` method for invoking the OpenAI API to get the next completion. The completion is returned from `run` and also added onto the transcript. The `transcript` method returns a copy of the entire transcript so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "isDdNwuUVYDv",
   "metadata": {
    "id": "isDdNwuUVYDv"
   },
   "outputs": [],
   "source": [
    "class TranscriptItem(TypedDict):\n",
    "    role: str\n",
    "    content: str\n",
    "Transcript = List[TranscriptItem]\n",
    "TranscriptIterable = Iterable[TranscriptItem]\n",
    "\n",
    "class BaseModelSpec(TypedDict):\n",
    "    developer_role: NotRequired[str]\n",
    "    frequency: NotRequired[float]\n",
    "    logit_bias: NotRequired[Dict[str, int]]\n",
    "    logprobs: NotRequired[bool]\n",
    "    max_completion_tokens: NotRequired[int]\n",
    "    max_tokens: NotRequired[int]\n",
    "    presence_penalty: NotRequired[float]\n",
    "    reasoning_effort: NotRequired[Literal['low', 'medium', 'high']]\n",
    "    seed: NotRequired[int]\n",
    "    service_tier: NotRequired[Literal['auto', 'default']]\n",
    "    stop: NotRequired[Union[Optional[str], List[str]]]\n",
    "    temperature: NotRequired[float]\n",
    "    top_logprobs: NotRequired[int]\n",
    "    top_p: NotRequired[float]\n",
    "\n",
    "class ProcessedModelSpec(BaseModelSpec):\n",
    "    model: str\n",
    "    messages: NotRequired[Transcript]\n",
    "\n",
    "class AgentRunner:\n",
    "    def __init__(self, client: openai.OpenAI, modelspec: ProcessedModelSpec):\n",
    "        self._client = client\n",
    "        self._args = modelspec.copy()\n",
    "        if 'developer_role' in self._args:\n",
    "            self._developer_role = self._args['developer_role']\n",
    "            del self._args['developer_role']\n",
    "        else:\n",
    "            self._developer_role = 'developer'\n",
    "        self._args['messages'] = []\n",
    "\n",
    "    def append(self, message: TranscriptItem):\n",
    "        if message['role'] == 'developer':\n",
    "            self.append_developer(message['content'])\n",
    "        else:\n",
    "            self._args['messages'].append(message)\n",
    "\n",
    "    def extend(self, messages: TranscriptIterable):\n",
    "        for message in messages:\n",
    "            self.append(message)\n",
    "\n",
    "    def append_developer(self, message: str):\n",
    "        self._args['messages'].append({\n",
    "            'role': self._developer_role,\n",
    "            'content': message,\n",
    "        })\n",
    "\n",
    "    def append_user(self, message: str):\n",
    "        self._args['messages'].append({\n",
    "            'role': 'user',\n",
    "            'content': message,\n",
    "        })\n",
    "\n",
    "    def append_assistant(self, message: str):\n",
    "        self._args['messages'].append({\n",
    "            'role': 'assistant',\n",
    "            'content': message,\n",
    "        })\n",
    "\n",
    "    def run(self, render_errors=False) -> str:\n",
    "        backoff = 15.\n",
    "        backoff_ratio = 2.\n",
    "        failures = 0\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                response = self._client.chat.completions.create(**cast(Any, self._args))\n",
    "                break\n",
    "            except (openai.RateLimitError, openai.APITimeoutError) as e:\n",
    "                if render_errors:\n",
    "                    print(e)\n",
    "                fuzzed_backoff = backoff * random.uniform(0.75, 1.333)\n",
    "                backoff *= backoff_ratio\n",
    "                time.sleep(fuzzed_backoff)\n",
    "            except openai.APIError as e:\n",
    "                if render_errors:\n",
    "                    print(e)\n",
    "                failures += 1\n",
    "                if failures >= 3:\n",
    "                    raise e\n",
    "                time.sleep(random.uniform(3, 7))\n",
    "        content = response.choices[0].message.content\n",
    "        self.append_assistant(content)\n",
    "        return content\n",
    "\n",
    "    def transcript(self) -> Transcript:\n",
    "        return copy.deepcopy(self._args['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Fce-q2L4jhlv",
   "metadata": {
    "id": "Fce-q2L4jhlv"
   },
   "source": [
    "`AgentRunnerFactory` generates `AgentRunner`s from higher-level configuration structures and initializes them with an appropriate prompt. It is constructed from a dictionary of `ClientSpec`s, a dictionary of `ModelSpec`s, and a `PromptSpec`. Each `ClientSpec` entry maps an identifying string to a dictionary of keyword arguments provided to the `openai.OpenAI` constructor. These arguments typically need to include at least a `base_url` and an `api_key`. A `ModelSpec` contains mostly the same entries as the `ProcessedModelSpec` above, and also must include a `client` entry, which is a reference into the `ClientSpec` dictionary indicating which client should be used to interact with this model. A `PromptSpec` contains `instructions` and a list of `sample_games`. Each element of the `sample_games` list contains arguments for constructing a `GeneratedGame` or a `FetchedGame`, and a `solution` which is a list of inputs which solve that game. The resulting prompt will contain the instructions, then walkthroughs constructed from the given solutions, and end with a repetition of the instructions. The factory's `build` method takes a `model` argument (a reference into the dictionary of `ModelSpec`s) and returns an `AgentRunner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "uOntuV28Nufc",
   "metadata": {
    "id": "uOntuV28Nufc"
   },
   "outputs": [],
   "source": [
    "class ClientSpec(TypedDict):\n",
    "    api_key: NotRequired[str]\n",
    "    organization: NotRequired[str]\n",
    "    project: NotRequired[str]\n",
    "    base_url: NotRequired[str]\n",
    "    websocket_base_url: NotRequired[str]\n",
    "    timeout: NotRequired[float]\n",
    "    max_retries: NotRequired[int]\n",
    "    default_headers: NotRequired[Mapping[str, str]]\n",
    "    default_query: NotRequired[Mapping[str, object]]\n",
    "\n",
    "class ModelSpec(BaseModelSpec):\n",
    "    client: str\n",
    "    model: NotRequired[str]\n",
    "    reasoner: NotRequired[bool]\n",
    "\n",
    "class FetchedSampleGame(TypedDict):\n",
    "    url: str\n",
    "    solution: List[str]\n",
    "    json_url: NotRequired[str]\n",
    "\n",
    "class GeneratedSampleGame(TypedDict):\n",
    "    seed: int\n",
    "    tw_make_args: List[str]\n",
    "    solution: List[str]\n",
    "\n",
    "SampleGame = Union[FetchedSampleGame, GeneratedSampleGame]\n",
    "\n",
    "class PromptSpec(TypedDict):\n",
    "    instructions: str\n",
    "    sample_games: List[SampleGame]\n",
    "\n",
    "class AgentRunnerFactory:\n",
    "    def __init__(\n",
    "            self,\n",
    "            client_specs: Dict[str, ClientSpec],\n",
    "            model_specs: Dict[str, ModelSpec],\n",
    "            prompt_spec: PromptSpec,\n",
    "            tw_make_bin : str = TW_MAKE_BIN,\n",
    "            game_dir : str = os.path.join(WORK_DIR, \"games\"),\n",
    "        ):\n",
    "        self._client_specs = client_specs.copy()\n",
    "        self._model_specs = model_specs.copy()\n",
    "        self._prompt_spec = prompt_spec.copy()\n",
    "        self._tw_make_bin = tw_make_bin\n",
    "        self._game_dir = game_dir\n",
    "        self._nonreasoner_prompt : Optional[Transcript] = None\n",
    "        self._reasoner_prompt : Optional[Transcript] = None\n",
    "\n",
    "        self._samples : List[Transcript] = []\n",
    "        for sample_spec in self._prompt_spec['sample_games']:\n",
    "            sample : Transcript = []\n",
    "            if 'url' in sample_spec:\n",
    "                sample_spec = cast(FetchedSampleGame, sample_spec)\n",
    "                game : Game = FetchedGame(\n",
    "                    sample_spec['url'],\n",
    "                    sample_spec.get('json_url')\n",
    "                )\n",
    "            elif 'seed' in sample_spec:\n",
    "                sample_spec = cast(GeneratedSampleGame, sample_spec)\n",
    "                game = GeneratedGame(\n",
    "                    sample_spec['seed'],\n",
    "                    sample_spec['tw_make_args'],\n",
    "                    tw_make_bin=self._tw_make_bin,\n",
    "                    game_dir=self._game_dir,\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"Sample game must contain a url or a seed and tw_make_args\"\n",
    "                )\n",
    "            game_runner = GameRunner(\n",
    "                game=game,\n",
    "                max_turns=len(sample_spec['solution']) + 1\n",
    "            )\n",
    "            sample.append({'role': 'user', 'content': game_runner.reset()})\n",
    "            outcome = None\n",
    "            for step in sample_spec['solution']:\n",
    "                assert not outcome\n",
    "                sample.append({'role': 'assistant', 'content': step})\n",
    "                obs, outcome = game_runner.step(step)\n",
    "                sample.append({'role': 'user', 'content': obs})\n",
    "            assert outcome != False\n",
    "            sample.append({'role': 'assistant', 'content': \"QUIT\"})\n",
    "            self._samples.append(sample)\n",
    "\n",
    "    def _get_nonreasoner_prompt(self) -> Transcript:\n",
    "        if self._nonreasoner_prompt is not None:\n",
    "            return self._nonreasoner_prompt\n",
    "        nonreasoner_prompt = [{\n",
    "            'role': 'developer',\n",
    "            'content': self._prompt_spec['instructions']\n",
    "        }]\n",
    "        for sample in self._samples:\n",
    "            nonreasoner_prompt.extend(sample)\n",
    "            nonreasoner_prompt.append({\n",
    "                'role': 'developer',\n",
    "                'content': \"Well done! Now play again. Your instructions are the \"\n",
    "                    \"same as before:\\n\\n\" + self._prompt_spec['instructions']\n",
    "            })\n",
    "\n",
    "        self._nonreasoner_prompt = nonreasoner_prompt\n",
    "        return self._nonreasoner_prompt\n",
    "\n",
    "    def _get_reasoner_prompt(self) -> Transcript:\n",
    "        if self._reasoner_prompt is not None:\n",
    "            return self._reasoner_prompt\n",
    "        instructions = self._prompt_spec['instructions']\n",
    "        if len(self._samples) == 1:\n",
    "            instructions += \"\\n\\nHere is a walkthrough of an example game:\\n\"\n",
    "        elif len(self._samples) > 1:\n",
    "            instructions += \"\\n\\nHere are some walkthroughs of example games:\\n\"\n",
    "\n",
    "        for sample in self._samples:\n",
    "            instructions += \"```\\n\"\n",
    "            for message in sample:\n",
    "                instructions += message['content']\n",
    "                if message['role'] == 'assistant':\n",
    "                    instructions += \"\\n\"\n",
    "            instructions += \"```\\n\"\n",
    "\n",
    "        if len(self._samples) > 0:\n",
    "            instructions += \"Now it's your turn!\"\n",
    "\n",
    "        self._reasoner_prompt = [{\n",
    "            'role': 'developer',\n",
    "            'content': instructions\n",
    "        }]\n",
    "        return self._reasoner_prompt\n",
    "\n",
    "    def get_prompt(self, model_name: str) -> Transcript:\n",
    "        model_spec = self._model_specs[model_name]\n",
    "        if model_spec.get('reasoner', False):\n",
    "            return self._get_reasoner_prompt()\n",
    "        else:\n",
    "            return self._get_nonreasoner_prompt()\n",
    "\n",
    "    def build(self, model_name: str) -> AgentRunner:\n",
    "        model_spec = self._model_specs[model_name]\n",
    "        client_spec = self._client_specs[model_spec['client']]\n",
    "\n",
    "        processed_spec : dict = cast(dict, model_spec.copy())\n",
    "        if 'client' in processed_spec:\n",
    "            del processed_spec['client']\n",
    "        if 'reasoner' in processed_spec:\n",
    "            del processed_spec['reasoner']\n",
    "        if 'model' not in processed_spec:\n",
    "            processed_spec['model'] = model_name\n",
    "\n",
    "        client = openai.OpenAI(**client_spec)\n",
    "        runner = AgentRunner(client, cast(ProcessedModelSpec, processed_spec))\n",
    "        if model_spec.get('reasoner', False):\n",
    "            runner.extend(self._get_reasoner_prompt())\n",
    "        else:\n",
    "            runner.extend(self._get_nonreasoner_prompt())\n",
    "        return runner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AL96QRIepjSG",
   "metadata": {
    "id": "AL96QRIepjSG"
   },
   "source": [
    "The `ExperimentRunner` puts everything together. An `ExperimentRunner` is constructed from a `ClientSpec` dictionary, a `ModelSpec` dictionary, instructions, a list of sample games, a list of `tw-make` arguments, and a turn limit. It can then `run` an experiment, given a list of models to be tested and a list of game seeds to test them against. Each model will play each seed up to `max_attempts` (default 3) times until it wins. Results are stored in `$WORK_DIR/experiments/<model>/<spec-hash>/<seed>/<attempt>.json`. The spec-hash is computed from the model spec, the tw-make arguments, and the prompt spec (containing instructions and sample games), and all these hash inputs are also recorded in a file named `spec.json`. Unless `run`'s `force_rerun` argument is set to `True`, any (model, spec, seed, attempt) combination will only be run once, and subsequent `run` invocations will just return those stored results.\n",
    "\n",
    "The entire game transcript is recorded as part of its result, but its outcome is summarized as one of:\n",
    "\n",
    "* \"won\": The game was won.\n",
    "* \"lost\": The game was lost, e.g. by improperly preparing an ingredient.\n",
    "* \"turnmax\": The turn limit was reached before any other outcome.\n",
    "* \"quit\": The agent quit out of the game befor otherwise finishing it.\n",
    "* \"silence\": The agent output something uninterpretable for five turns in a row.\n",
    "* \"error\": Either the game crashed, or OpenAI APIs calls errored out several times in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6VBw-0lXsM3L",
   "metadata": {
    "id": "6VBw-0lXsM3L"
   },
   "outputs": [],
   "source": [
    "Outcome = Literal['won', 'lost', 'turnmax', 'silence', 'quit', 'error']\n",
    "class GameResult(TypedDict):\n",
    "    model: str\n",
    "    tw_make_args: List[str]\n",
    "    seed: int\n",
    "    error: Optional[str]\n",
    "    outcome: Outcome\n",
    "    messages: Transcript\n",
    "    turns: int\n",
    "\n",
    "class ExperimentRunner:\n",
    "    def __init__(\n",
    "            self,\n",
    "            client_specs: Dict[str, ClientSpec],\n",
    "            model_specs: Dict[str, ModelSpec],\n",
    "            instructions: str,\n",
    "            sample_games: List[SampleGame],\n",
    "            tw_make_args: List[str],\n",
    "            max_turns: int  = 100,\n",
    "            old_error_wording: bool = False,\n",
    "            max_silences: int = 5,\n",
    "            tw_make_bin : str = TW_MAKE_BIN,\n",
    "            experiment_dir : str = os.path.join(WORK_DIR, \"experiments\"),\n",
    "            game_dir : str = os.path.join(WORK_DIR, \"games\"),\n",
    "        ):\n",
    "        self._client_specs = copy.deepcopy(client_specs)\n",
    "        self._model_specs = copy.deepcopy(model_specs)\n",
    "        self._prompt_spec : PromptSpec = {\n",
    "            'instructions': instructions,\n",
    "            'sample_games': sample_games,\n",
    "        }\n",
    "        self._tw_make_args = tw_make_args.copy()\n",
    "        self._max_turns = max_turns\n",
    "        self._old_error_wording = old_error_wording\n",
    "        self._max_silences = max_silences\n",
    "        self._tw_make_bin = tw_make_bin\n",
    "        self._experiment_dir = experiment_dir\n",
    "        self._game_dir = game_dir\n",
    "        self._agent_runner_factory = AgentRunnerFactory(\n",
    "            self._client_specs,\n",
    "            self._model_specs,\n",
    "            self._prompt_spec,\n",
    "            tw_make_bin=self._tw_make_bin,\n",
    "            game_dir=self._game_dir,\n",
    "        )\n",
    "\n",
    "    def experiment_spec(self, model: str) -> dict:\n",
    "        canonicalized_model_spec = cast(dict, self._model_specs[model].copy())\n",
    "        if 'model' not in canonicalized_model_spec:\n",
    "            canonicalized_model_spec['model'] = model\n",
    "        del canonicalized_model_spec['client']\n",
    "\n",
    "        experiment_spec = {\n",
    "            'model_spec': canonicalized_model_spec,\n",
    "            'prompt_spec': self._prompt_spec,\n",
    "            'tw_make_args': self._tw_make_args,\n",
    "            'max_turns': self._max_turns,\n",
    "            'old_error_wording': self._old_error_wording,\n",
    "            'max_silences': self._max_silences,\n",
    "        }\n",
    "\n",
    "        hash_input = json.dumps(experiment_spec, sort_keys=True)\n",
    "        hash = hashlib.sha256(hash_input.encode()).hexdigest()\n",
    "        experiment_spec['hash'] = hash\n",
    "        return experiment_spec\n",
    "\n",
    "    def write_spec(self, model: str):\n",
    "        experiment_spec = self.experiment_spec(model)\n",
    "        model_dir = os.path.join(self._experiment_dir, model, experiment_spec['hash'])\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        spec_file = os.path.join(model_dir, \"spec.json\")\n",
    "        if not os.path.exists(spec_file):\n",
    "            json.dump(experiment_spec, open(spec_file, 'w'), indent=4, sort_keys=True)\n",
    "\n",
    "    def get_prompt(self, model: str):\n",
    "        return self._agent_runner_factory.get_prompt(model)\n",
    "\n",
    "    def _interact(self, agent: AgentRunner, game: GameRunner, render=False) -> dict:\n",
    "        obs = game.reset()\n",
    "        agent.append_user(obs)\n",
    "        if render:\n",
    "            print(obs)\n",
    "        outcome = None\n",
    "        silences = 0\n",
    "        turns = 0\n",
    "        while not outcome:\n",
    "            try:\n",
    "                action = agent.run(render_errors=render)\n",
    "            except openai.APIError as e:\n",
    "                return {\n",
    "                    'error': str(e),\n",
    "                    'outcome': 'error',\n",
    "                    'messages': agent.transcript(),\n",
    "                    'turns': turns,\n",
    "                }\n",
    "            if render:\n",
    "                print(action)\n",
    "\n",
    "            turns += 1\n",
    "\n",
    "            try:\n",
    "                obs, outcome = game.step(action)\n",
    "            except GameRunnerException as e:\n",
    "                silences += 1\n",
    "                if silences >= self._max_silences:\n",
    "                    return {\n",
    "                        'error': None,\n",
    "                        'outcome': 'silence',\n",
    "                        'messages': agent.transcript(),\n",
    "                        'turns': turns,\n",
    "                    }\n",
    "                if self._old_error_wording:\n",
    "                    agent.append_developer(e.old_message)\n",
    "                else:\n",
    "                    agent.append_developer(str(e))\n",
    "                continue\n",
    "            agent.append_user(obs)\n",
    "            if render:\n",
    "                print(obs)\n",
    "            silences = 0\n",
    "\n",
    "        return {\n",
    "            'error': None,\n",
    "            'outcome': outcome,\n",
    "            'messages': agent.transcript(),\n",
    "            'turns': turns,\n",
    "        }\n",
    "\n",
    "    def run_single(\n",
    "            self,\n",
    "            model: str,\n",
    "            seed: int,\n",
    "            attempt: int = 0,\n",
    "            render: bool = False,\n",
    "            force_rerun: Optional[bool] = None,\n",
    "            save: bool = True,\n",
    "    ) -> GameResult:\n",
    "        experiment_spec = self.experiment_spec(model)\n",
    "        model_dir = os.path.join(self._experiment_dir, model, experiment_spec['hash'])\n",
    "        seed_dir = os.path.join(model_dir, str(seed))\n",
    "        attempt_path = os.path.join(seed_dir, str(attempt) + \".json\")\n",
    "\n",
    "        os.makedirs(seed_dir, exist_ok=True)\n",
    "        if force_rerun != True and os.path.exists(attempt_path):\n",
    "            return json.load(open(attempt_path, 'r'))\n",
    "        if force_rerun == False:\n",
    "            raise RuntimeError(\n",
    "                \"Failed to load model {} spec {} seed {} attempt {}\".format(\n",
    "                    model,\n",
    "                    experiment_spec['hash'],\n",
    "                    seed,\n",
    "                    attempt\n",
    "                )\n",
    "            )\n",
    "\n",
    "        agent_runner = self._agent_runner_factory.build(model)\n",
    "        game = GeneratedGame(\n",
    "            seed,\n",
    "            self._tw_make_args,\n",
    "            tw_make_bin=self._tw_make_bin,\n",
    "            game_dir=self._game_dir,\n",
    "        )\n",
    "        game_runner = GameRunner(game=game, max_turns=self._max_turns)\n",
    "        result = self._interact(agent_runner, game_runner, render=render)\n",
    "        result['model'] = model\n",
    "        result['tw_make_args'] = self._tw_make_args.copy()\n",
    "        result['seed'] = seed\n",
    "        if save:\n",
    "            json.dump(result, open(attempt_path, 'w'), indent=4, sort_keys=True)\n",
    "        return cast(GameResult, result)\n",
    "\n",
    "    def run_to_success(\n",
    "            self,\n",
    "            model: str,\n",
    "            seed: int,\n",
    "            max_attempts: int = 3,\n",
    "            max_errors: int = 3,\n",
    "            render: bool = False,\n",
    "            force_rerun: Optional[bool] = None,\n",
    "            save: bool = True,\n",
    "    ) -> List[GameResult]:\n",
    "        nonerrored_attempts = 0\n",
    "        errored_attempts = 0\n",
    "        attempt = 0\n",
    "        results = []\n",
    "\n",
    "        while nonerrored_attempts < max_attempts and errored_attempts < max_errors:\n",
    "            result = self.run_single(\n",
    "                model,\n",
    "                seed,\n",
    "                attempt=attempt,\n",
    "                render=render,\n",
    "                force_rerun=force_rerun,\n",
    "                save=save)\n",
    "            results.append(result)\n",
    "            if result['outcome'] == 'won':\n",
    "                return results\n",
    "            elif result['outcome'] == 'error':\n",
    "                errored_attempts += 1\n",
    "            nonerrored_attempts += 1\n",
    "            attempt += 1\n",
    "        return results\n",
    "\n",
    "    def pregenerate_games(\n",
    "            self,\n",
    "            seeds: Union[int, Iterable[int]],\n",
    "        ):\n",
    "        if isinstance(seeds, int):\n",
    "            seeds = [seeds]\n",
    "        with multiprocessing.Pool() as pool:\n",
    "            pool.starmap(\n",
    "                _pregenerate_game_worker,\n",
    "                 [\n",
    "                     (seed, self._tw_make_args, self._tw_make_bin, self._game_dir)\n",
    "                    for seed in seeds\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def run(\n",
    "            self,\n",
    "            models: Union[str, Iterable[str]],\n",
    "            seeds: Union[int, Iterable[int]],\n",
    "            max_attempts: int = 3,\n",
    "            max_errors: int = 3,\n",
    "            processes: int = 1,\n",
    "            render: bool = False,\n",
    "            force_rerun: Optional[bool] = None,\n",
    "            save: bool = True,\n",
    "        ) -> List[List[GameResult]]:\n",
    "\n",
    "        if isinstance(models, str):\n",
    "            models = [models]\n",
    "        if isinstance(seeds, int):\n",
    "            seeds = [seeds]\n",
    "\n",
    "        for model in models:\n",
    "            self.write_spec(model)\n",
    "        self.pregenerate_games(seeds)\n",
    "        with multiprocessing.Pool(processes=processes) as pool:\n",
    "            return pool.starmap(\n",
    "                _run_worker,\n",
    "                [\n",
    "                    (self, model, seed, max_attempts, max_errors, force_rerun, save)\n",
    "                    for model in models\n",
    "                    for seed in seeds\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def download(self):\n",
    "        try:\n",
    "            from google.colab import files\n",
    "        except ImportError as e:\n",
    "            raise RuntimeError(\n",
    "                \"Download failed: this notebook is not running in Google Colab.\"\n",
    "            ) from e\n",
    "\n",
    "        os.makedirs(self._experiment_dir, exist_ok=True)\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            tar_filename = os.path.join(temp_dir, f\"experiment.tar.gz\")\n",
    "            with tarfile.open(tar_filename, \"w:gz\") as tar:\n",
    "                tar.add(\n",
    "                    self._experiment_dir,\n",
    "                    arcname=os.path.basename(self._experiment_dir)\n",
    "                )\n",
    "\n",
    "            files.download(tar_filename)\n",
    "\n",
    "def _pregenerate_game_worker(seed, tw_make_args, tw_make_bin, game_dir):\n",
    "    GeneratedGame(\n",
    "        seed,\n",
    "        tw_make_args,\n",
    "        tw_make_bin=tw_make_bin,\n",
    "        game_dir=game_dir,\n",
    "    )\n",
    "\n",
    "def _run_worker(\n",
    "        runner, model, seed, max_attempts, max_errors, force_rerun, save\n",
    "    ) -> List[GameResult]:\n",
    "    return runner.run_to_success(\n",
    "        model, seed, max_attempts, max_errors, force_rerun=force_rerun, save=save\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fUqLSqeOsJVY",
   "metadata": {
    "id": "fUqLSqeOsJVY"
   },
   "source": [
    "## Analysis code\n",
    "\n",
    "The following code generates performance summaries for each model, determining their win rate by their n'th attempt.\n",
    "\n",
    "The `credible_intervals` method generate Bayesian credible intervals on these wins rates, treating each seed as a uniquely-biased coin drawn from a population with an unknown distribution of biases. For the first attempt, the bounds of the credible interval are simply quantiles of a beta distribution with parameters $\\alpha = \\textrm{wins} + 0.5$ and $\\beta = \\textrm{losses} + 0.5$, but since we're retrying specifically those seeds which were failed on earlier attempts, the later distributions have no clean analytic form, so numerical methods are required; we use a Monte Carlo sim.\n",
    "\n",
    "The `test_improvement` method tests whether one experiment produced a statistically significant improvement over another, using a single-tailed stratified Fisher exact test, which is an exact alternative to the Cochran–Mantel–Haenszel test. This exactitude comes at the cost of computational complexity: for $M$ models with $N$ seeds tested, it is $O(M\\cdot N^M)$. Fortunately, for $M=4$ and $N=100$ this is still tractable and should execute in a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nVIuFJGjx6Ms",
   "metadata": {
    "id": "nVIuFJGjx6Ms"
   },
   "outputs": [],
   "source": [
    "import numpy as np, scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "oEWKcDIcsNpY",
   "metadata": {
    "id": "oEWKcDIcsNpY"
   },
   "outputs": [],
   "source": [
    "OutcomeCounts = Dict[Outcome, int]\n",
    "OutcomeList = List[OutcomeCounts]\n",
    "OutcomeTable = Dict[str, OutcomeList]\n",
    "\n",
    "class Analyzer:\n",
    "    def __init__(self, all_results: List[List[GameResult]]):\n",
    "        self._all_results = all_results\n",
    "        self._filtered_results = []\n",
    "        for result_list in self._all_results:\n",
    "            filtered = [ result for result in result_list if result['outcome'] != 'error']\n",
    "            self._filtered_results.append(filtered)\n",
    "        self._results_by_model : Dict[str, List[List[GameResult]]] = dict()\n",
    "\n",
    "        self._max_attempts = 0\n",
    "        for results_list in self._filtered_results:\n",
    "            self._max_attempts = max(self._max_attempts, len(results_list))\n",
    "\n",
    "        for results_list in self._filtered_results:\n",
    "            model = results_list[0]['model']\n",
    "            if model not in self._results_by_model:\n",
    "                self._results_by_model[model] = list()\n",
    "            self._results_by_model[model].append(results_list)\n",
    "\n",
    "        self._outcomes : OutcomeTable = dict()\n",
    "\n",
    "        for model, all_model_results in self._results_by_model.items():\n",
    "            model_outcomes : OutcomeList = [dict() for _ in range(self._max_attempts)]\n",
    "            for attempt in range(self._max_attempts):\n",
    "                for results in all_model_results:\n",
    "                    if attempt < len(results):\n",
    "                        outcome = results[attempt]['outcome']\n",
    "                        if outcome not in model_outcomes[attempt]:\n",
    "                            model_outcomes[attempt][outcome] = 0\n",
    "                        model_outcomes[attempt][outcome] += 1\n",
    "\n",
    "            self._outcomes[model] = model_outcomes\n",
    "\n",
    "        self._cumulative_outcomes : OutcomeTable = dict()\n",
    "        for model, outcomes in self._outcomes.items():\n",
    "            incremental_outcome = self._outcomes[model][0].copy()\n",
    "            self._cumulative_outcomes[model] = [incremental_outcome.copy()]\n",
    "            for attempt in range(1, self._max_attempts):\n",
    "                for outcome, count in self._outcomes[model][attempt].items():\n",
    "                    if outcome not in incremental_outcome:\n",
    "                        incremental_outcome[outcome] = 0\n",
    "                    incremental_outcome[outcome] += count\n",
    "                self._cumulative_outcomes[model].append(incremental_outcome.copy())\n",
    "\n",
    "\n",
    "    def outcomes(self) -> OutcomeTable:\n",
    "        return copy.deepcopy(self._outcomes)\n",
    "\n",
    "    def cumulative_outcomes(self) -> OutcomeTable:\n",
    "        return copy.deepcopy(self._cumulative_outcomes)\n",
    "\n",
    "    def _model_credible_intervals(\n",
    "            self,\n",
    "            model : str,\n",
    "            prior_a : float = 0.5,\n",
    "            prior_b : float = 0.5,\n",
    "            conf_level : float = 0.95,\n",
    "            nsamples: int = 1000000\n",
    "        ) -> List[Tuple[float, float]]:\n",
    "\n",
    "        intervals = []\n",
    "        cumulative = np.zeros(nsamples)\n",
    "        lower_quantile = (1 - conf_level) / 2.0\n",
    "        upper_quantile = (1 + conf_level) / 2.0\n",
    "        remaining = len(self._results_by_model[model])\n",
    "        wins_by_attempt = [\n",
    "            self._outcomes[model][n].get('won',0)\n",
    "            for n in range(self._max_attempts)\n",
    "        ]\n",
    "\n",
    "        for wins in wins_by_attempt:\n",
    "            a = wins + prior_a\n",
    "            b = (remaining - wins) + prior_b\n",
    "            p_samples = scipy.stats.beta.rvs(a, b, size=nsamples)\n",
    "            cumulative += (1 - cumulative) * p_samples\n",
    "            ci = np.quantile(cumulative, [lower_quantile, upper_quantile])\n",
    "            intervals.append((ci[0], ci[1]))\n",
    "            remaining -= wins\n",
    "\n",
    "        return intervals\n",
    "\n",
    "    def credible_intervals(\n",
    "            self,\n",
    "            prior_a : float = 0.5,\n",
    "            prior_b : float = 0.5,\n",
    "            conf_level : float = 0.95,\n",
    "            nsamples: int = 1000000\n",
    "        ) -> Dict[str, List[Tuple[float, float]]]:\n",
    "        intervals = dict()\n",
    "        for model in self._outcomes.keys():\n",
    "            intervals[model] = self._model_credible_intervals(\n",
    "                model, prior_a, prior_b, conf_level, nsamples\n",
    "            )\n",
    "        return intervals\n",
    "\n",
    "    def _stratified_fisher_exact(\n",
    "            self,\n",
    "            control : np.ndarray,\n",
    "            treatment: np.ndarray\n",
    "        ) -> float:\n",
    "\n",
    "        # Validate input shapes\n",
    "        M = control.shape[0]\n",
    "        if control.shape != (M, 2) or treatment.shape != (M, 2):\n",
    "            raise ValueError(\"control and treatment must be of shape (M, 2)\")\n",
    "\n",
    "        # Compute observed test statistic (sum of a_i)\n",
    "        S_observed = np.sum(treatment[:, 0])\n",
    "\n",
    "        # Lists to store bounds and probabilities for each stratum\n",
    "        lb_list = []\n",
    "        ub_list = []\n",
    "        probs_list = []\n",
    "\n",
    "        # Process each stratum\n",
    "        for i in range(M):\n",
    "            # Compute row and column totals\n",
    "            n1_i = treatment[i, 0] + treatment[i, 1]  # Treatment total\n",
    "            n2_i = control[i, 0] + control[i, 1]      # Control total\n",
    "            m1_i = treatment[i, 0] + control[i, 0]    # Responsive total\n",
    "            N_i = n1_i + n2_i                          # Grand total\n",
    "\n",
    "            # Determine range for a_i\n",
    "            lb_i = max(0, n1_i + m1_i - N_i)\n",
    "            ub_i = min(n1_i, m1_i)\n",
    "\n",
    "            # Compute possible values of a_i and their probabilities\n",
    "            possible_a_i = np.arange(lb_i, ub_i + 1)\n",
    "            probs_i = scipy.stats.hypergeom.pmf(possible_a_i, N_i, m1_i, n1_i)\n",
    "\n",
    "            lb_list.append(lb_i)\n",
    "            ub_list.append(ub_i)\n",
    "            probs_list.append(probs_i)\n",
    "\n",
    "        # Compute p-value by enumerating all possible combinations\n",
    "        p_value = 0.0\n",
    "        for combination in itertools.product(\n",
    "                *[range(lb, ub + 1) for lb, ub in zip(lb_list, ub_list)]\n",
    "            ):\n",
    "            # Compute sum of a_i for this combination\n",
    "            S = sum(combination)\n",
    "            # Compute probability as product across strata\n",
    "            P = np.prod([probs_list[i][combination[i] - lb_list[i]] for i in range(M)])\n",
    "            # Add to p-value if S is as extreme or more extreme\n",
    "            if S >= S_observed:\n",
    "                p_value += P\n",
    "\n",
    "        return p_value\n",
    "\n",
    "    def test_improvement(self, newer):\n",
    "        common_models = frozenset(self._results_by_model.keys()) & \\\n",
    "            frozenset(newer._results_by_model.keys())\n",
    "        control = []\n",
    "        treatment = []\n",
    "\n",
    "        for model in common_models:\n",
    "            control_total = sum(self._outcomes[model][0].values())\n",
    "            treatment_total = sum(newer._outcomes[model][0].values())\n",
    "            control_wins = self._outcomes[model][0].get('won', 0)\n",
    "            treatment_wins = newer._outcomes[model][0].get('won', 0)\n",
    "            control_losses = control_total - control_wins\n",
    "            treatment_losses = treatment_total - treatment_wins\n",
    "            control.append((control_wins, control_losses))\n",
    "            treatment.append((treatment_wins, treatment_losses))\n",
    "        return self._stratified_fisher_exact(np.asarray(control), np.asarray(treatment))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6aa53e97-137a-40bf-a24f-91a9e9e875f7",
   "metadata": {
    "id": "EUtxAdbWzXRf"
   },
   "source": [
    "## First Experiment\n",
    "\n",
    "The first of the two experiments used a naively-written prompt, crafted based on usual best practices for prompt engineering but without the benefit of seeing how it would perform, and a walkthrough derived from the sample game on the TextWorld website. Tested models included gpt-4o (version 2024-08-06), gpt-4o-mini (version 2024-07-18), Llama3.1-405B-Instruct-FP8, and Llama3.3-70B-Instruct-FP8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8xKeHe_iEGbR",
   "metadata": {
    "id": "8xKeHe_iEGbR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3844/1270726539.py:12: UserWarning: Failed to retrieve API key for openai_api_key. Set it in Colab secrets or via the OPENAI_API_KEY environment variable.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3844/1270726539.py:12: UserWarning: Failed to retrieve API key for lambdalabs_api_key. Set it in Colab secrets or via the LAMBDALABS_API_KEY environment variable.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "CLIENTS : Dict[str, ClientSpec] = {\n",
    "    'openai': {\n",
    "        'base_url': \"https://api.openai.com/v1\",\n",
    "        'api_key': get_api_key(\"openai_api_key\"),\n",
    "    },\n",
    "    'lambdalabs': {\n",
    "        'base_url': \"https://api.lambdalabs.com/v1\",\n",
    "        'api_key': get_api_key(\"lambdalabs_api_key\"),\n",
    "    },\n",
    "}\n",
    "\n",
    "MODELS : Dict[str, ModelSpec] = {\n",
    "    'gpt-4o': {'client': 'openai'},\n",
    "    'gpt-4o-mini': {'client': 'openai'},\n",
    "    'llama3.1-405b-instruct-fp8': {\n",
    "        'client': 'lambdalabs'\n",
    "    },\n",
    "    'llama3.3-70b-instruct-fp8': {\n",
    "        'client': 'lambdalabs',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tQnaGNTQ18Nw",
   "metadata": {
    "id": "tQnaGNTQ18Nw"
   },
   "outputs": [],
   "source": [
    "TW_MAKE_ARGS : List[str] = [\n",
    "    \"tw-cooking\", \"--recipe\",\"3\", \"--take\", \"2\", \"--go\", \"12\", \"--open\", \"--cook\",\n",
    "    \"--cut\", \"--drop\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "NBQoGxr03S6G",
   "metadata": {
    "id": "NBQoGxr03S6G"
   },
   "outputs": [],
   "source": [
    "MAX_TURNS : int = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "wEc9lYQEBGgY",
   "metadata": {
    "id": "wEc9lYQEBGgY"
   },
   "outputs": [],
   "source": [
    "INSTRUCTIONS : str = \\\n",
    "\"\"\"You are going to play a text adventure game. All of the user's input\n",
    "represents text printed by the game. Your output will be interpreted\n",
    "as commands issued to the game. However, the game will ignore\n",
    "anything you put in parentheses. Use parentheticals to record your\n",
    "thoughts as you think step-by-step through these instructions before\n",
    "you decide what move to make. Every time you enter a new room, begin\n",
    "your next thought by listing what exits you see.\n",
    "\n",
    "The game you will be playing is randomly generated, but all games\n",
    "follow the same simple template. Your goal is to prepare and eat a\n",
    "meal. To do this, you will perform the following, three-phase\n",
    "procedure.\n",
    "\n",
    "# Phase I: Find the kitchen\n",
    "\n",
    "Explore the map until you locate the kitchen. Use compass commands\n",
    "`N`, `S`, `E`, and `W` to move around. There may be doors in your\n",
    "way. Use the command `OPEN <adjective> DOOR` to open them,\n",
    "substituting whatever adjective you see in the room description.\n",
    "\n",
    "When you explore, pay careful attention to any occurrence of \"north\",\n",
    "\"south\", \"east\", or \"west\" in a room description. These words always\n",
    "indicate room exits. Explore all exits until you've located\n",
    "everything you need.\n",
    "\n",
    "During this phase, make a note of any items you come across, but do\n",
    "not pick any of them up.\n",
    "\n",
    "# Phase II: Search for ingredients\n",
    "\n",
    "Once you find the kitchen, use the command `READ COOKBOOK`. The\n",
    "cookbook will contain a list of ingredients, and then a list of\n",
    "directions for preparation. Right now, just pay attention to the\n",
    "list of ingredients. Don't worry about preparation until Phase III.\n",
    "\n",
    "Next, use the command `I` to list your inventory. You may already be\n",
    "carrying some of the ingredients you need. If you are carrying\n",
    "anything that you *don't* need, use the `DROP` command to drop it.\n",
    "You may find some items in your inventory that you didn't pick up,\n",
    "which were there at the start of the game. This is normal.\n",
    "\n",
    "Third, use the command `OPEN FRIDGE`. If the fridge contains any\n",
    "ingredients you need, use the `GET` command to pick them up.\n",
    "\n",
    "Now, figure out what ingredients you are still missing, and then\n",
    "continue exploring the map until you find them.\n",
    "\n",
    "Pick up only the ingredients that the recipe calls for. Pay\n",
    "attention to their entire description. For example, if the recipe\n",
    "calls for a red pepper, don't pick up a yellow pepper unles the\n",
    "recipe needs that too.\n",
    "\n",
    "If you try to pick something up and the game tells you, \"You're\n",
    "carrying too many things already\", you've messed up: either you're\n",
    "carrying something you don't need, or you don't need the thing\n",
    "you're trying to pick up.  Check your inventory again (use `I`),\n",
    "compare your inventory against the recipe, and `DROP` any\n",
    "unnecessary items.\n",
    "\n",
    "If you get lost or stuck in a loop while exploring in Phase II,\n",
    "remember the principles from Phase I: look for \"north\", \"south\",\n",
    "\"east\", and \"west\" in room descriptions to make sure you haven't\n",
    "overlooked any exits. If you notice a closed door, that's certainly\n",
    "a way you haven't explored yet.\n",
    "\n",
    "# Phase III: Prepare your meal\n",
    "\n",
    "Once you have all your ingredients, return to the kitchen. Now\n",
    "`READ COOKBOOK` again, and then check your inventory again.\n",
    "Double-check that your inventory contains all the required\n",
    "ingredients and nothing else. If you made a mistake, return to\n",
    "phase II and correct it.\n",
    "\n",
    "Now you are ready to follow the directions in the cookbook. Each\n",
    "step except the last one in the list of directions is either a\n",
    "cutting step, or a cooking step. A cutting step calls for you either\n",
    "to *slice*, *dice*, or *chop* an ingredient. A cooking step calls\n",
    "for you either to *roast*, *fry*, or *grill* an ingredient.\n",
    "\n",
    "Determine if any steps involve cutting. If and only if you need to\n",
    "cut anything, use `GET KNIFE` to pick up the knife. You might have\n",
    "to drop something first to make room for the knife in your inventory.\n",
    "\n",
    "Now, follow the directions in order and follow them exactly. Use the\n",
    "following commands:\n",
    "\n",
    "* If the cookbook says to *slice* an ingredient, use `SLICE <ingredient> WITH KNIFE`.\n",
    "* If the cookbook says to *dice* an ingredient, use `DICE <ingredient> WITH KNIFE`.\n",
    "* If the cookbook says to *chop* an ingredient, use `CHOP <ingredient> WITH KNIFE`.\n",
    "* If the cookbook says to *roast* an ingredient, use `COOK <ingredient> WITH OVEN`.\n",
    "* If the cookbook says to *fry* an ingredient, use `COOK <ingredient> WITH STOVE`.\n",
    "* If the cookbook says to *grill* an ingredient, use `COOK <ingredient> WITH BBQ`.\n",
    "\n",
    "Be careful to use the right verb for cutting and the right appliance\n",
    "for cooking! If you slice something that you should have diced or\n",
    "chopped, or if you roast something that you should have fried or\n",
    "grilled, you'll lose the game. Also be sure not to cook any\n",
    "ingredient more than once, or you'll burn it.\n",
    "\n",
    "Everything you need for meal preparation is in the kitchen, except\n",
    "for the BBQ. The BBQ is in the backyard. So, if you have to grill\n",
    "something, you will have to go to the backyard first and then return\n",
    "to the kitchen afterward. After you get back to the kitchen, you\n",
    "should `READ COOKBOOK` again so you can remember where you left off.\n",
    "\n",
    "The final step in the list of directions will be \"prepare meal\", so\n",
    "once you have done everything else, use `PREPARE MEAL` to put the\n",
    "ingredients together; make sure you're still holding them all. You\n",
    "can drop the knife now if you need to. Finally, use the command\n",
    "`EAT MEAL` to win the game, and then `QUIT`.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd4df6e8-8ef2-45bd-894e-5ea92b641c00",
   "metadata": {
    "id": "dd4df6e8-8ef2-45bd-894e-5ea92b641c00"
   },
   "outputs": [],
   "source": [
    "SAMPLE_GAMES : List[SampleGame] = [\n",
    "    {\n",
    "        'url': (\n",
    "            \"https://textworldparchmentserver.z13.web.core.windows.net/games/game1.z8\"\n",
    "        ),\n",
    "        'solution': [\n",
    "            \"(I see exits to the south, east, and west. I'm in Phase I, searching for \"\n",
    "                \"the kitchen. I've started the game in the backyard, where the BBQ is. \"\n",
    "                \"That isn't important right now, but I'll remember it for later in \"\n",
    "                \"case I need to grill something. Let's try the east exit first.) E\",\n",
    "            \"(I see an exit to the west. Looks like this is a dead end with nothing \"\n",
    "                \"useful, so I'll go back west) W\",\n",
    "            \"(I see exits to the south, east, and west.  I'll search westward next, \"\n",
    "                \"but first I need to open the door in my way) OPEN WOODEN DOOR\",\n",
    "            \"(Now that the door is open, the path west is clear) W\",\n",
    "            \"(I see an exit to the east. Another dead end. The toolbox and workbench \"\n",
    "                \"aren't useful.) E\",\n",
    "            \"(I see exits to the south, east, and west.  I've checked east and west, \"\n",
    "                \"so only south remains. There's another door there I need to open.) \"\n",
    "                \"OPEN SCREEN DOOR\",\n",
    "            \"(Now my way south is clear.) S\",\n",
    "            \"(I see exits to the north, south, east, and west. I found the kitchen, \"\n",
    "                \"so I'm in Phase II now. The first thing to do in Phase II is read \"\n",
    "                \"the cookbook.) READ COOKBOOK\",\n",
    "            \"(Okay, I'm looking for a black papper, a chicken leg, and milk. Do I \"\n",
    "                \"already have any of that?) I\",\n",
    "            \"(No, there's nothing in my inventory. So there's nothing I need to drop, \"\n",
    "                \"but three ingredients to search for. The fridge is the first place \"\n",
    "                \"to search.) OPEN FRIDGE\",\n",
    "            \"(That raw chicken leg is one of my three ingredients, so I should pick \"\n",
    "                \"it up. The wing isn't an ingredient, so I'll ignore that.) \"\n",
    "                \"GET RAW CHICKEN LEG\",\n",
    "            \"(That's one ingredient down, two I'm still searching for. I see there \"\n",
    "                \"are exits from here in all four directions, but I've already explored \"\n",
    "                \"everything to the north. Let's try west.)  OPEN FROSTED-GLASS DOOR\",\n",
    "            \"(Now my path west is clear.) W\",\n",
    "            \"(I see an exit to the east. I don't need flour, so there's nothing useful \"\n",
    "                \"here, and it's a dead end.) E\",\n",
    "            \"(I see exits to the north, south, east, and west. The east and south \"\n",
    "                \"exits are still unexplored. Let's go east.) E\",\n",
    "            \"(I see exits to the south and west. There's nothing useful here, but \"\n",
    "                \"there's an unexplored exit to the south.) S\",\n",
    "            \"(I see exits to the north and west. Again nothing useful here, but \"\n",
    "                \"another unexplored exit to the west.) W\",\n",
    "            \"(I see exits to the north, east, and west. In my last three turns I went \"\n",
    "                \"east, south, and west from the kitchen, so that north exit probably \"\n",
    "                \"takes me back to the kitchen. West seems like the most promising \"\n",
    "                \"direction for further exploration, but I need to open the door \"\n",
    "                \"first.) OPEN FRONT DOOR\",\n",
    "            \"(Now my way west is clear.) W\",\n",
    "            \"(I see exits to the east and west. There's nothing useful here, but \"\n",
    "                \"there's an explored exit to the west.) W\",\n",
    "            \"(I see exits to the north and east. Again nothing useful here, but \"\n",
    "                \"there's a door to the north.) OPEN SLIDING DOOR\",\n",
    "            \"(Now my way north is clear.) N\",\n",
    "            \"(I see an exit to the south. Jackpot! This room has both of the \"\n",
    "                \"ingredients I'm still searching for. First, the black pepper.) \"\n",
    "                \"GET BLACK PEPPER\",\n",
    "            \"(I also need the milk.) GET MILK\",\n",
    "            \"(I don't need the red hot pepper or the salt. I have all my ingredients \"\n",
    "                \"now, which means I'm in Phase III and should return to the kitchen \"\n",
    "                \"by going back the way I came.) S\",\n",
    "            \"(I see exits to the north and east. The house is back east.) E\",\n",
    "            \"(I see exits to the east and west. I'll go east again to re-enter the \"\n",
    "                \"house.) E\",\n",
    "            \"(I see exits to the north, east, and west. Okay, now I'm back in this \"\n",
    "                \"corridor. I speculated earlier that north would be a shortcut back \"\n",
    "                \"to the kitchen.) N\",\n",
    "            \"(I see exits to the north, south, east, and west. I'm back in the \"\n",
    "                \"kitchen, so it's time to re-read the cookbook.) READ COOKBOOK\",\n",
    "            \"(Now I'll check my inventory to double-check that I have all the \"\n",
    "                \"ingredients.) I\",\n",
    "            \"(The ingredients I need are a black pepper, chicken leg, and milk. That \"\n",
    "                \"exactly matches my inventory, so that means I did everything right \"\n",
    "                \"so far and can proceed with the directions. Sice none of the \"\n",
    "                \"directions involve cutting, I can ignore the knife. The first \"\n",
    "                \"direction says to roast the chicken leg. When I need to roast \"\n",
    "                \"something, I use the oven. I mustn't use the stove or the BBQ; \"\n",
    "                \"I'd lose the game if I did that.)  COOK RAW CHICKEN LEG WITH OVEN\",\n",
    "            \"(Okay, checking my inventory one more time: I should still be holding \"\n",
    "                \"all the now-cooked ingredients.) I\",\n",
    "            \"(Right. I'm still holding the now-roasted chicken leg, as well as milk \"\n",
    "                \"and the black pepper which didn't need any preparation. Now, the \"\n",
    "                \"final step in the directions is to prepare the meal, and I should be \"\n",
    "                \"ready for that.) PREPARE MEAL\",\n",
    "            \"(Finally, I can eat the meal. This should win the game.) EAT MEAL\",\n",
    "        ],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "Xg-G4fYmX_cz",
   "metadata": {
    "id": "Xg-G4fYmX_cz"
   },
   "outputs": [],
   "source": [
    "FIRST_EXPERIMENT = ExperimentRunner(\n",
    "    CLIENTS, MODELS, INSTRUCTIONS, SAMPLE_GAMES, TW_MAKE_ARGS, MAX_TURNS,\n",
    "    old_error_wording=True, max_silences=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cLG_i0f3Vyu",
   "metadata": {
    "id": "9cLG_i0f3Vyu"
   },
   "outputs": [],
   "source": [
    "FIRST_RESULTS = FIRST_EXPERIMENT.run(\n",
    "    ['gpt-4o', 'gpt-4o-mini', 'llama3.3-70b-instruct-fp8', 'llama3.1-405b-instruct-fp8'],\n",
    "    range(1,101),\n",
    "    processes=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "zwx5nLSK_Z3e",
   "metadata": {
    "id": "zwx5nLSK_Z3e"
   },
   "outputs": [],
   "source": [
    "FIRST_ANALYSIS=Analyzer(FIRST_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fWBVz3u43tqY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWBVz3u43tqY",
    "outputId": "3643b0f3-18a5-41cc-a886-057d5377eed0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o': [{'won': 89, 'lost': 4, 'quit': 7},\n",
       "  {'won': 98, 'lost': 4, 'quit': 9},\n",
       "  {'won': 100, 'lost': 4, 'quit': 9}],\n",
       " 'gpt-4o-mini': [{'won': 23,\n",
       "   'lost': 13,\n",
       "   'turnmax': 46,\n",
       "   'silence': 10,\n",
       "   'quit': 8},\n",
       "  {'won': 30, 'lost': 20, 'turnmax': 91, 'silence': 16, 'quit': 20},\n",
       "  {'won': 34, 'lost': 34, 'turnmax': 132, 'silence': 20, 'quit': 26}],\n",
       " 'llama3.3-70b-instruct-fp8': [{'quit': 19,\n",
       "   'won': 57,\n",
       "   'turnmax': 18,\n",
       "   'lost': 5,\n",
       "   'silence': 1},\n",
       "  {'quit': 24, 'won': 80, 'turnmax': 28, 'lost': 9, 'silence': 2},\n",
       "  {'quit': 30, 'won': 85, 'turnmax': 35, 'lost': 10, 'silence': 2}],\n",
       " 'llama3.1-405b-instruct-fp8': [{'won': 89,\n",
       "   'quit': 8,\n",
       "   'turnmax': 2,\n",
       "   'silence': 1},\n",
       "  {'won': 100, 'quit': 8, 'turnmax': 2, 'silence': 1},\n",
       "  {'won': 100, 'quit': 8, 'turnmax': 2, 'silence': 1}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIRST_ANALYSIS.cumulative_outcomes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ajRuJSZW2o02",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajRuJSZW2o02",
    "outputId": "18b325b4-6528-4475-d9c1-08b90e30e028"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o': [(np.float64(0.8176599439045491), np.float64(0.9401947149438062)),\n",
       "  (np.float64(0.9397817055253157), np.float64(0.9960141965954791)),\n",
       "  (np.float64(0.9796514577389814), np.float64(0.9999963387696768))],\n",
       " 'gpt-4o-mini': [(np.float64(0.15602731257411376),\n",
       "   np.float64(0.319449950676573)),\n",
       "  (np.float64(0.22086876029921393), np.float64(0.3993258761470935)),\n",
       "  (np.float64(0.2610240006936727), np.float64(0.44552987489473))],\n",
       " 'llama3.3-70b-instruct-fp8': [(np.float64(0.4720833257968957),\n",
       "   np.float64(0.6639479025556048)),\n",
       "  (np.float64(0.7165785737975244), np.float64(0.8708052193954307)),\n",
       "  (np.float64(0.7772788956122636), np.float64(0.9133834308307244))],\n",
       " 'llama3.1-405b-instruct-fp8': [(np.float64(0.8176389827271875),\n",
       "   np.float64(0.940064104783628)),\n",
       "  (np.float64(0.9763556037370433), np.float64(0.999995352549931)),\n",
       "  (np.float64(0.9848338366767211), np.float64(0.999999740603284))]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIRST_ANALYSIS.credible_intervals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vRXS5cD6c4MN",
   "metadata": {
    "id": "vRXS5cD6c4MN"
   },
   "source": [
    "## Second experiment\n",
    "\n",
    "For the second experiment, the instructions were slightly revised to place more emphasis on systematic exploration. The walkthrough from the TextWorld website's example game was replaced with one based on the same difficulty settings used for the test, using a seed selected for having a particularly difficult map in order to better illustrate how to navigate. Furthermore, the error messages presented to the agent when it provides uninterpretable input were revised, and the threshold for giving up after consecutive uninterpretable responses was raised from 3 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3nme2fIc8jOO",
   "metadata": {
    "id": "3nme2fIc8jOO"
   },
   "outputs": [],
   "source": [
    "NEW_INSTRUCTIONS = \\\n",
    "\"\"\"You are going to play a text adventure game. All of the user's input represents\n",
    "text printed by the game. On each turn, consider the information that was just\n",
    "presented to you, plan your next move, and then make it. Place your thoughts\n",
    "inside parentheses, and then outside those parentheses, issue a command to the\n",
    "game. The game will interpret all of, and only, what is not parenthesized as a\n",
    "command.\n",
    "\n",
    "Maintain a calm and coherent tone at all times. Although the game's prose is often\n",
    "awkward and disjointed, you should not imitate that style.\n",
    "\n",
    "The game you will be playing is randomly generated, but all games follow the\n",
    "same simple template. Your goal is to prepare and eat a meal. To do this, you\n",
    "will perform a three-phase procedure. In the first phase, you will search for\n",
    "the kitchen. In the second phase, you will read the cookbook to determine what\n",
    "ingredients you need and then gather those ingredients. In the third phase,\n",
    "you will return to the kitchen with the ingredients and then prepare and eat\n",
    "the meal.\n",
    "\n",
    "# Phase I: Find the kitchen\n",
    "\n",
    "Explore the map until you locate the kitchen. Use compass commands `N`, `S`,\n",
    "`E`, and `W` to move around. There may be doors in your way. Use the command\n",
    "`OPEN <adjective> DOOR` to open them, substituting whatever adjective you see in\n",
    "the room description.\n",
    "\n",
    "When you explore, pay careful attention to any occurrence of \"north\", \"south\",\n",
    "\"east\", or \"west\" in a room description. These words always indicate room exits.\n",
    "Structure your exploration systematically and \"depth-first\", preferring first to\n",
    "explore new avenues but backtracking once you've exhausted any particular\n",
    "branch.\n",
    "\n",
    "During this phase, make a note of any items you come across, but do not pick any\n",
    "of them up.\n",
    "\n",
    "# Phase II: Search for ingredients\n",
    "\n",
    "Once you find the kitchen, use the command `READ COOKBOOK`. The cookbook will\n",
    "contain a list of ingredients, and then a list of directions for preparation.\n",
    "Right now, just pay attention to the list of ingredients. Don't worry about\n",
    "preparation until Phase III.\n",
    "\n",
    "Next, use the command `I` to list your inventory. You may already be carrying\n",
    "some of the ingredients you need. If you are carrying anything that you *don't*\n",
    "need, use the `DROP` command to drop it. You may find some items in your\n",
    "inventory that you didn't pick up, which were there at the start of the game.\n",
    "This is normal.\n",
    "\n",
    "Third, use the command `OPEN FRIDGE`. If the fridge contains any ingredients you\n",
    "need, use the `GET` command to pick them up.\n",
    "\n",
    "Now, figure out what ingredients you are still missing, and then continue\n",
    "exploring the map until you find them. Resume your exploration in the same\n",
    "systematic fashion that you began it in the earlier phase.\n",
    "\n",
    "Pick up only the ingredients that the recipe calls for. Pay attention to their\n",
    "entire description. For example, if the recipe calls for a red pepper, don't\n",
    "pick up a yellow pepper unles the recipe needs that too.\n",
    "\n",
    "If you try to pick something up and the game tells you, \"You're carrying too\n",
    "many things already\", you've messed up: either you're carrying something you\n",
    "don't need, or you don't need the thing you're trying to pick up.  Check your\n",
    "inventory again (use `I`), compare your inventory against the recipe, and `DROP`\n",
    "any unnecessary items.\n",
    "\n",
    "If you get stuck searching for an ingredient, don't give up: it's always\n",
    "somewhere accessible and there's probably somewhere you forgot to explore.\n",
    "Instead of wandering in circles, try clearing your mind and beginning a fresh,\n",
    "systematic, depth-first traversal of the whole map.\n",
    "\n",
    "\n",
    "# Phase III: Prepare your meal\n",
    "\n",
    "Once you have all your ingredients, return to the kitchen. Now `READ COOKBOOK`\n",
    "again, and then check your inventory again. Double-check that your inventory\n",
    "contains all the required ingredients and nothing else. If you made a mistake,\n",
    "return to phase II and correct it.\n",
    "\n",
    "Now you are ready to follow the directions in the cookbook. Each step except the\n",
    "last one in the list of directions is either a cutting step, or a cooking step.\n",
    "A cutting step calls for you either to *slice*, *dice*, or *chop* an ingredient.\n",
    "A cooking step calls for you either to *roast*, *fry*, or *grill* an ingredient.\n",
    "\n",
    "Determine if any steps involve cutting. If and only if you need to cut anything,\n",
    "use `GET KNIFE` to pick up the knife. You might have to drop something first to\n",
    "make room for the knife in your inventory.\n",
    "\n",
    "Now, follow the directions in order and follow them exactly. Use the following\n",
    "commands:\n",
    "\n",
    "* If the cookbook says to *slice* an ingredient, use `SLICE <ingredient> WITH KNIFE`.\n",
    "* If the cookbook says to *dice* an ingredient, use `DICE <ingredient> WITH KNIFE`.\n",
    "* If the cookbook says to *chop* an ingredient, use `CHOP <ingredient> WITH KNIFE`.\n",
    "* If the cookbook says to *roast* an ingredient, use `COOK <ingredient> WITH OVEN`.\n",
    "* If the cookbook says to *fry* an ingredient, use `COOK <ingredient> WITH STOVE`.\n",
    "* If the cookbook says to *grill* an ingredient, use `COOK <ingredient> WITH BBQ`.\n",
    "\n",
    "Be careful to use the right verb for cutting and the right appliance for\n",
    "cooking! If you slice something that you should have diced or chopped, or if you\n",
    "roast something that you should have fried or grilled, you'll lose the game.\n",
    "Also be sure not to cook any ingredient more than once, or you'll burn it.\n",
    "\n",
    "Everything you need for meal preparation is in the kitchen, except for the BBQ.\n",
    "The BBQ is in the backyard. So, if you have to grill something, you will have to\n",
    "go to the backyard first and then return to the kitchen afterward. After you get\n",
    "back to the kitchen, you should `READ COOKBOOK` again so you can remember where\n",
    "you left off.\n",
    "\n",
    "The final step in the list of directions will be \"prepare meal\", so once you\n",
    "have done everything else, use `PREPARE MEAL` to put the ingredients together;\n",
    "make sure you're still holding them all. You can drop the knife now if you need\n",
    "to. Finally, use the command `EAT MEAL` to win the game, and then `QUIT`.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7p9N0kTOFWfK",
   "metadata": {
    "id": "7p9N0kTOFWfK"
   },
   "outputs": [],
   "source": [
    "NEW_SAMPLE_GAMES = [{\n",
    "    'seed': 65531,\n",
    "    'tw_make_args': TW_MAKE_ARGS,\n",
    "    'solution': [\n",
    "        \"(I've started in the bathroom. The only exit is to the south. I don't see \"\n",
    "            \"anything useful here, so I'll just take that exit.) S\",\n",
    "        \"(I see exits to the north, east, and west. I just came from the north, but \"\n",
    "            \"east and west would be equally good ways to continue exploring. Let's \"\n",
    "            \"try west first.) W\",\n",
    "        \"(I see exits to the south, east, and west, with the east one being the way \"\n",
    "            \"I just came and the south and west being unexplored. But since I've found \"\n",
    "            \"the kitchen, I'm now in phase II and there are some things to do here \"\n",
    "            \"before I continue exploring. The first step of phase II is to read the \"\n",
    "            \"cookbook.) READ COOKBOOK\",\n",
    "        \"(I'm looking for a block of cheese, a red bell pepper, and a red tuna. Now \"\n",
    "            \"let's see what's already in my inventory.) I\",\n",
    "        \"(My inventory contains a raw red tuna, a raw red potato, and a raw white \"\n",
    "            \"tuna. The red tuna is one of the ingredients I need, but I don't need \"\n",
    "            \"the other two items, so I'll drop those.) DROP RAW RED POTATO\",\n",
    "        \"(I also need to drop the raw white tuna.) DROP RAW WHITE TUNA\",\n",
    "        \"(Now that my inventory is squared away, I should search the fridge.) \"\n",
    "            \"OPEN FRIDGE\",\n",
    "        \"(Opening the fridge didn't report any contents, so it's probably empty, but \"\n",
    "            \"I'll double-check.) LOOK IN FRIDGE\",\n",
    "        \"(Yes, it's empty. Now it's time to continue searching for ingredients. I \"\n",
    "            \"left off with unexplored exits to the west and south. I got here from the \"\n",
    "            \"east, and there's also more back there to explore, but I'll continue \"\n",
    "            \"forward first prior to backtracking. Let's go west.) W\",\n",
    "        \"(Now I see exits to the north, east, and south, with the north and south \"\n",
    "            \"being unexplored. There are no ingredients in this room, so I should \"\n",
    "            \"continue exploring. Let's go north. Since there's a door in that \"\n",
    "            \"direction, I first need to open it.) OPEN FRONT DOOR\",\n",
    "        \"(Now my way north is clear.) N\",\n",
    "        \"(I see exits to the north and south. There are no ingredients here. I came \"\n",
    "            \"from the south, so north is the way to continue exploration.) N\",\n",
    "        \"(I see exits to the south and east. Same situation as last turn: no \"\n",
    "            \"ingredients, two exits, and one of those is back the way I came so \"\n",
    "            \"I'll take the unexplored one to the east. That one has a door which I \"\n",
    "            \"need to open.) OPEN COMMERCIAL GLASS DOOR\",\n",
    "        \"(Now my way east is clear.) E\",\n",
    "        \"(I've reached a dead end, with only one exit back to the west. However, that \"\n",
    "            \"block of cheese is one of the ingredients I'm searching for, so I'll pick \"\n",
    "            \"it up.) GET BLOCK OF CHEESE\",\n",
    "        \"(Now I still need to locate the red bell pepper. Since I'm at a dead end, \"\n",
    "            \"I need to begin backtracking.) W\",\n",
    "        \"(Only two possible exits here, both explored, so I continue backtracking by \"\n",
    "            \"taking the one to the south.) S\",\n",
    "        \"(My situation is similar to last turn: I'm backtracking until I find \"\n",
    "            \"somewhere new to explore. There's nowhere new here, so I'll continue \"\n",
    "            \"backtracking to the south.) S\",\n",
    "        \"(Now I'm back in the living room, which has exits to the north, south, and \"\n",
    "            \"east. I just came from the north and have fully explored that branch now. \"\n",
    "            \"Earlier I got here from the kitchen, which is to the east. But I haven't \"\n",
    "            \"explored south from here yet, so I'll do that next.) S\",\n",
    "        \"(This is a dead end, with the only exit back to the north. The red bell \"\n",
    "            \"pepper isn't here, so there's nothing to do but go back.) N\",\n",
    "        \"(I'm back in the living room again. I've finished exploring everything to \"\n",
    "            \"the north and south, so now I need to backtrack east.) E\",\n",
    "        \"(I'm back in the kitchen, but since I'm still missing the red bell pepper \"\n",
    "            \"I need to keep exploring. There are exits to the west, south, and east. \"\n",
    "            \"I just came from the west. East takes me back the way I got here \"\n",
    "            \"originally during phase I. South is unexplored, so I should go that way \"\n",
    "            \"after I've opened the door.) OPEN FROSTED-GLASS DOOR\",\n",
    "        \"(Now my way south is clear.) S\",\n",
    "        \"(Another dead end, and no red bell pepper. Nothing to do but go back north.) \"\n",
    "            \"N\",\n",
    "        \"(I've now thoroughly explored to the west and the south, so my only remaining \"\n",
    "            \"option is to backtrack again to the east.) E\",\n",
    "        \"(I'm now back in the corridor, where I haven't been since phase I. There are \"\n",
    "            \"exits north, east, and west. I just came from the west, and at the very \"\n",
    "            \"beginning of the game I got here from the north. The closed door to the \"\n",
    "            \"east reminds me that I haven't checked there yet, so I should open it \"\n",
    "            \"and then head that way.) OPEN SCREEN DOOR\",\n",
    "        \"(Now my way east is clear.) E\",\n",
    "        \"(I see exits to the west, south, and north. I also notice the BBQ here, which \"\n",
    "            \"I don't need yet but I'll remember it's here. I just came from the west, \"\n",
    "            \"and can explore to the north or south. Let's try north.) N\",\n",
    "        \"(This is a dead end with the only exit back south, but I found the red bell \"\n",
    "            \"pepper that I've been looking for, so I'll pick it up.) GET RED BELL \"\n",
    "            \"PEPPER\",\n",
    "        \"(That was my last ingredient, so now I'm in phase III. I can ignore the red \"\n",
    "            \"onion and the green hot pepper and start heading back to the kitchen.) S\",\n",
    "        \"(I'm back in the backyard. There are exits to the north, west and south. I \"\n",
    "            \"just came from the north. The way back to the kitchen is west. I haven't \"\n",
    "            \"explored south yet, but since I already have my ingredients and I also \"\n",
    "            \"know where the BBQ is, there's no need for further exploration and I \"\n",
    "            \"can continue back to the kitchen.) W\",\n",
    "        \"(I'm back in the corridor again, with exits to the west, north, and east. \"\n",
    "            \"West should take me to the kitchen.) W\",\n",
    "        \"(I've reached the kitchen. Now for a sanity-check, I'm going to re-read \"\n",
    "            \"the cookbook and then check my inventory.) READ COOKBOOK\",\n",
    "        \"(The cookbook reminds me that I should be carrying a block of cheese, a red \"\n",
    "            \"bell pepper, and a red tuna. I'll make sure my inventory matches.) I\",\n",
    "        \"(Good, that's a match. Now I can start following the directions in the \"\n",
    "            \"cookbook. Since the recipe begins with slicing, I need to pick up the \"\n",
    "            \"knife.) GET KNIFE\",\n",
    "        \"(It seems my inventory is full, so I need to drop something to make room for \"\n",
    "            \"the knife. Everything I'm holding is a necessary ingredient, but I won't \"\n",
    "            \"need the red tuna right away so I can put that down for the time being.) \"\n",
    "            \"DROP RAW RED TUNA\",\n",
    "        \"(Now I should be able to pick up the knife.) GET KNIFE\",\n",
    "        \"(Now I can follow the first step of the recipe, which is to slice the block \"\n",
    "            \"of cheese.) SLICE BLOCK OF CHEESE WITH KNIFE\",\n",
    "        \"(Next I need to grill the block of cheese. For that I need the BBQ, so I \"\n",
    "            \"need to leave the kitchen for the backyard. Fortunately I've already been \"\n",
    "            \"there and I remember the way.) E\",\n",
    "        \"(I need to continue east again to get to the backyard.) E\",\n",
    "        \"(Now I'm in the backyard and can grill the cheese.) \"\n",
    "            \"COOK BLOCK OF CHEESE WITH BBQ\",\n",
    "        \"(Now that the cheese is grilled, I can return to the kitchen to continue the \"\n",
    "            \"recipe.) W\",\n",
    "        \"(The kitchen is to the west again.) W\",\n",
    "        \"(I'll check the cookbook one more time to remember where I left off.) \"\n",
    "            \"READ COOKBOOK\",\n",
    "        \"(I just finished grilling the block of cheese, so the next step is to dice \"\n",
    "            \"the red bell pepper.) DICE RED BELL PEPPER WITH KNIFE\",\n",
    "        \"(Next I need to fry the red bell pepper. I need to remember that frying \"\n",
    "            \"uses the stove. If I tried to use a different appliance I'd lose the \"\n",
    "            \"game.) COOK RED BELL PEPPER WITH STOVE\",\n",
    "        \"(Now I need to dice the red tuna, but I'm not holding it because I put it \"\n",
    "            \"down earlier to make room in my inventory for the knife. Since my \"\n",
    "            \"inventory is full again and I still need knife, I need to put something \"\n",
    "            \"different down to make room for the red tuna. I'm finished now with the \"\n",
    "            \"block of cheese and with the red bell pepper, so I can put one of those \"\n",
    "            \"down. Let's choose the pepper.) DROP RED BELL PEPPER\",\n",
    "        \"(Now I have room to pick up the tuna.) GET RED TUNA\",\n",
    "        \"(Now that I'm holding the tuna and the knife, I can dice it according to \"\n",
    "            \"the recipe.) DICE RED TUNA WITH KNIFE\",\n",
    "        \"(The next step in the recipe is to fry the red tuna. Again, I need to use the \"\n",
    "            \"stove to fry anything.) COOK RED TUNA WITH STOVE\",\n",
    "        \"(Now I need to prepare the meal. Before I can do that, I need to have all \"\n",
    "            \"the ingredients in my inventory, including the red bell pepper which I \"\n",
    "            \"set down earlier. Now that I'm finished with the knife, I can drop it.) \"\n",
    "            \"DROP KNIFE\",\n",
    "        \"(Now I have room to pick up the red bell pepper.) GET RED BELL PEPPER\",\n",
    "        \"(Now that I'm holding all the ingredients, I can prepare the meal.) PREPARE \"\n",
    "            \"MEAL\",\n",
    "        \"(Now I can eat the meal. This should win the game.) EAT MEAL\"\n",
    "    ]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "KkGxPZFztVrU",
   "metadata": {
    "id": "KkGxPZFztVrU"
   },
   "outputs": [],
   "source": [
    "SECOND_EXPERIMENT = ExperimentRunner(\n",
    "    CLIENTS, MODELS, NEW_INSTRUCTIONS, NEW_SAMPLE_GAMES, TW_MAKE_ARGS, MAX_TURNS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "Epbx1dSmvxzh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Epbx1dSmvxzh",
    "outputId": "8e35b29b-46b4-4358-d272-ac9596a433b7"
   },
   "outputs": [],
   "source": [
    "SECOND_RESULTS = SECOND_EXPERIMENT.run(\n",
    "    ['gpt-4o', 'gpt-4o-mini', 'llama3.3-70b-instruct-fp8', 'llama3.1-405b-instruct-fp8'],\n",
    "    range(101, 201),\n",
    "    processes=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "N-IxVnVI_jip",
   "metadata": {
    "id": "N-IxVnVI_jip"
   },
   "outputs": [],
   "source": [
    "SECOND_ANALYSIS = Analyzer(SECOND_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "FSaQ4Cmx3A7q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSaQ4Cmx3A7q",
    "outputId": "d0fbe0ea-019b-475f-9125-54cf532a86ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o': [{'won': 94, 'quit': 4, 'turnmax': 2},\n",
       "  {'won': 97, 'quit': 6, 'turnmax': 3},\n",
       "  {'won': 98, 'quit': 8, 'turnmax': 3}],\n",
       " 'gpt-4o-mini': [{'won': 32, 'turnmax': 52, 'quit': 9, 'lost': 7},\n",
       "  {'won': 40, 'turnmax': 96, 'quit': 13, 'lost': 19},\n",
       "  {'won': 50, 'turnmax': 139, 'quit': 15, 'lost': 24}],\n",
       " 'llama3.3-70b-instruct-fp8': [{'turnmax': 22,\n",
       "   'won': 64,\n",
       "   'quit': 12,\n",
       "   'lost': 2},\n",
       "  {'turnmax': 30, 'won': 84, 'quit': 18, 'lost': 4},\n",
       "  {'turnmax': 36, 'won': 91, 'quit': 20, 'lost': 5}],\n",
       " 'llama3.1-405b-instruct-fp8': [{'won': 96, 'turnmax': 1, 'quit': 3},\n",
       "  {'won': 100, 'turnmax': 1, 'quit': 3},\n",
       "  {'won': 100, 'turnmax': 1, 'quit': 3}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SECOND_ANALYSIS.cumulative_outcomes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "lFoQy-H83CiW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lFoQy-H83CiW",
    "outputId": "d90e61ac-e65b-4de9-a162-3a8f0818c8b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o': [(np.float64(0.8804934023073464), np.float64(0.9745901000827414)),\n",
       "  (np.float64(0.9263563355558441), np.float64(0.9922915632034028)),\n",
       "  (np.float64(0.946468364729441), np.float64(0.9969659481918016))],\n",
       " 'gpt-4o-mini': [(np.float64(0.23463582261070445),\n",
       "   np.float64(0.41550577526337756)),\n",
       "  (np.float64(0.31202237901659136), np.float64(0.5018336444284139)),\n",
       "  (np.float64(0.4108726603891476), np.float64(0.6039170341734513))],\n",
       " 'llama3.3-70b-instruct-fp8': [(np.float64(0.5429515076980874),\n",
       "   np.float64(0.7289977262938208)),\n",
       "  (np.float64(0.7618373748476049), np.float64(0.903272051823542)),\n",
       "  (np.float64(0.8480345871691255), np.float64(0.9568176730272397))],\n",
       " 'llama3.1-405b-instruct-fp8': [(np.float64(0.9076498833353197),\n",
       "   np.float64(0.9863765591588373)),\n",
       "  (np.float64(0.9774688951782196), np.float64(0.999995710864218)),\n",
       "  (np.float64(0.9855870657238253), np.float64(0.999999760222345))]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SECOND_ANALYSIS.credible_intervals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988fc3c6-41ec-418b-9b92-1f51f51beb80",
   "metadata": {},
   "source": [
    "The following p-value checks whether the second experiment was a statistically significant improvement on the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7Ypx1Srl8rxo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Ypx1Srl8rxo",
    "outputId": "db0be17c-8eab-4f15-cfa8-8a40924aa1e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.006298504998073345)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIRST_ANALYSIS.test_improvement(SECOND_ANALYSIS)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "fUqLSqeOsJVY",
    "BDN3YXYdyH8X",
    "vRXS5cD6c4MN"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
