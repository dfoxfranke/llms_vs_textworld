{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LLMs vs. TextWorld\n",
        "\n",
        "This notebook tests and proves the hypothesis that modern, off-the-shelf LLMs — even non-reasoning models such as GPT-4o — can achieve high win rates in TextWorld when given a detailed prompt and a walkthrough of an example game, *without* any task-specific training. Games are generated via `tw-cooking --recipe 3 --take 2 --go 12 --open --cook --cut --drop`, essentially configuring them for maximum difficulty. Of the four models tested, the best-performing is Llama-3.1-405B-Instruct-FP8, which won at 89 out of 100 seeds on its first attempt, and all 100 within two attempts. Difficulty navigating the map is the most common source of failure."
      ],
      "metadata": {
        "id": "4CNwHtetx1XP"
      },
      "id": "4CNwHtetx1XP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment setup"
      ],
      "metadata": {
        "id": "QluFBqjcyA0n"
      },
      "id": "QluFBqjcyA0n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need to pip-install some prerequisites and locate the `tw-make` binary."
      ],
      "metadata": {
        "id": "Xa1ZDHAntwOO"
      },
      "id": "Xa1ZDHAntwOO"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4e62d7ff-746d-4052-a9e8-42a2c52d9fe3",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e62d7ff-746d-4052-a9e8-42a2c52d9fe3",
        "outputId": "87ac7d18-1c8c-4c5e-f08e-e66648c4d9ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textworld in /usr/local/lib/python3.11/dist-packages (1.6.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.11/dist-packages (from textworld) (1.26.4)\n",
            "Requirement already satisfied: tqdm>=4.17.1 in /usr/local/lib/python3.11/dist-packages (from textworld) (4.67.1)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from textworld) (1.17.1)\n",
            "Requirement already satisfied: networkx>=2 in /usr/local/lib/python3.11/dist-packages (from textworld) (3.4.2)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from textworld) (10.6.0)\n",
            "Requirement already satisfied: tatsu==5.8.3 in /usr/local/lib/python3.11/dist-packages (from textworld) (5.8.3)\n",
            "Requirement already satisfied: hashids>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from textworld) (1.3.1)\n",
            "Requirement already satisfied: jericho>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from textworld) (3.3.0)\n",
            "Requirement already satisfied: mementos>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from textworld) (1.3.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from textworld) (2.5.0)\n",
            "Requirement already satisfied: prompt_toolkit in /usr/local/lib/python3.11/dist-packages (from textworld) (3.0.50)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.0->textworld) (2.22)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from jericho>=3.3.0->textworld) (3.7.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt_toolkit->textworld) (0.2.13)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (0.15.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (2.32.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (2.3.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.1.0->jericho>=3.3.0->textworld) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.1.0->jericho>=3.3.0->textworld) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy>=2.1.0->jericho>=3.3.0->textworld) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "import os.path, sys, sysconfig\n",
        "!{sys.executable} -m pip install textworld openai\n",
        "TW_MAKE_BIN : str = os.path.join(sysconfig.get_path(\"scripts\"), \"tw-make\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next cell defines a function for accessing API keys. It supports getting them from Colab's secret store or from environment variables. You may need to modify it if you want to access them through some other mechanism."
      ],
      "metadata": {
        "id": "ZMpYJtUvt6-m"
      },
      "id": "ZMpYJtUvt6-m"
    },
    {
      "cell_type": "code",
      "source": [
        "import os, warnings\n",
        "def get_api_key(service : str) -> str:\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "\n",
        "        secret = userdata.get(service)\n",
        "        if secret is not None:\n",
        "            return secret\n",
        "    except ImportError:\n",
        "        pass\n",
        "    secret = os.environ.get(service.upper())\n",
        "    if secret is None:\n",
        "        warnings.warn(\n",
        "            \"Failed to retrieve API key for {}. Set it in Colab secrets \"\n",
        "            \"or via the {} environment variable.\".format(\n",
        "                service, service.upper()\n",
        "            )\n",
        "        )\n",
        "    return secret"
      ],
      "metadata": {
        "id": "0gQxwL5mtD7D"
      },
      "id": "0gQxwL5mtD7D",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we define `WORK_DIR`, where we'll store generated games and experimental results. We'll use a Google Drive if we're running in Colab, otherwise use the Jupyter data directory. You might want to customize this."
      ],
      "metadata": {
        "id": "r_IgLxj7uoHw"
      },
      "id": "r_IgLxj7uoHw"
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path, jupyter_core\n",
        "\n",
        "USE_GOOGLE_DRIVE : bool = True\n",
        "OFFLINE_WORK_DIR : str = os.path.join(\n",
        "    jupyter_core.paths.jupyter_data_dir(),\n",
        "\"textworld\")\n",
        "ONLINE_WORK_DIR : str = \"/content/drive/MyDrive/textworld\"\n",
        "\n",
        "if USE_GOOGLE_DRIVE:\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount(\"/content/drive\", force_remount=True)\n",
        "        WORK_DIR : str = ONLINE_WORK_DIR\n",
        "    except ImportError:\n",
        "        WORK_DIR = OFFLINE_WORK_DIR\n",
        "else:\n",
        "    WORK_DIR = OFFLINE_WORK_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJeBXu_VvC5D",
        "outputId": "ec8b7289-4dcc-44b9-d773-bd3fdbd37a1a"
      },
      "id": "xJeBXu_VvC5D",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook supports testing any model compatible with the [OpenAI chat completion API](https://platform.openai.com/docs/api-reference/chat). The two variable definitions below can be extended to configure additional models. `CLIENTS` is a dictionary whose keys are arbitrary identifiers and whose values are dictionaries of arguments to the `OpenAI` constructor. `MODELS` is a dictionary whose keys are arbitrary identifiers and whose values are dictionaries which use the following keys:\n",
        "\n",
        "* `'client'` (required) takes a string value which points into `CLIENTS` to determine how to construct the client used with this model.\n",
        "* `'developer_role'` (optional) gives a role name to associate with the developer prompt, if different from \"developer\". Some models call this role \"system\", and some models don't support customizing the developer prompt in which case this should be set to \"user\".\n",
        "* Any other key is interpreted as a keyword argument to be provided to `OpenAI.chat.completions.create`. If you don't provide a `model` argument here, then the key that you used to name this `MODELS` entry is used."
      ],
      "metadata": {
        "id": "880Xgoj9ELin"
      },
      "id": "880Xgoj9ELin"
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Any\n",
        "\n",
        "CLIENTS : Dict[str, Dict[str, Any]] = {\n",
        "    'openai': {\n",
        "        'base_url': \"https://api.openai.com/v1\",\n",
        "        'api_key': get_api_key(\"openai_api_key\"),\n",
        "    },\n",
        "    'lambdalabs': {\n",
        "        'base_url': \"https://api.lambdalabs.com/v1\",\n",
        "        'api_key': get_api_key(\"lambdalabs_api_key\"),\n",
        "    },\n",
        "}\n",
        "\n",
        "MODELS : Dict[str, Dict[str, Any]] = {\n",
        "    'gpt-4o': {'client': 'openai'},\n",
        "    'gpt-4o-mini': {'client': 'openai'},\n",
        "    'llama3.1-405b-instruct-fp8': {\n",
        "        'client': 'lambdalabs'\n",
        "    },\n",
        "    'llama3.3-70b-instruct-fp8': {\n",
        "        'client': 'lambdalabs',\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "8xKeHe_iEGbR"
      },
      "id": "8xKeHe_iEGbR",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment"
      ],
      "metadata": {
        "id": "BDN3YXYdyH8X"
      },
      "id": "BDN3YXYdyH8X"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now our environment is set up and we can configure the parameters of the experiment. `TW_MAKE_ARGS` lists what arguments we'll pass to `tw-make` when generating games. See [command reference](https://textworld.readthedocs.io/en/latest/textworld.challenges.cooking.html). This configures our games' difficulty, and we're going for more-or-less the maximum:\n",
        "\n",
        "* The recipe has three ingredients.\n",
        "* One is already inventory, two must be searched for.\n",
        "* The map has 12 rooms.\n",
        "* The map is full of doors which must be opened before proceeding.\n",
        "* Recipe preparation requires cooking steps and cutting steps.\n",
        "* The agent will have to drop items in order to juggle around inventory limits."
      ],
      "metadata": {
        "id": "OX-p0C300VNJ"
      },
      "id": "OX-p0C300VNJ"
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "TW_MAKE_ARGS : List[str] = [\n",
        "    \"tw-cooking\", \"--recipe\",\"3\", \"--take\", \"2\", \"--go\", \"12\", \"--open\", \"--cook\",\n",
        "    \"--cut\", \"--drop\",\n",
        "]"
      ],
      "metadata": {
        "id": "tQnaGNTQ18Nw"
      },
      "id": "tQnaGNTQ18Nw",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`MAX_TURNS` controls how many turns the agent is allowed in which to complete the game before the run is considered a failure. 100 gives a decent amount of leeway while still creating some time pressure."
      ],
      "metadata": {
        "id": "XnoKeSr82m8z"
      },
      "id": "XnoKeSr82m8z"
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TURNS : int = 100"
      ],
      "metadata": {
        "id": "NBQoGxr03S6G"
      },
      "id": "NBQoGxr03S6G",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`INSTRUCTIONS` defines the developer prompt. A well-worded prompt is key to getting good results. The one here follows conventional best practices for prompt engineering but has not been particularly optimized."
      ],
      "metadata": {
        "id": "pOnU8LtU3skw"
      },
      "id": "pOnU8LtU3skw"
    },
    {
      "cell_type": "code",
      "source": [
        "INSTRUCTIONS : str = \\\n",
        "\"\"\"You are going to play a text adventure game. All of the user's input\n",
        "represents text printed by the game. Your output will be interpreted\n",
        "as commands issued to the game. However, the game will ignore\n",
        "anything you put in parentheses. Use parentheticals to record your\n",
        "thoughts as you think step-by-step through these instructions before\n",
        "you decide what move to make. Every time you enter a new room, begin\n",
        "your next thought by listing what exits you see.\n",
        "\n",
        "The game you will be playing is randomly generated, but all games\n",
        "follow the same simple template. Your goal is to prepare and eat a\n",
        "meal. To do this, you will perform the following, three-phase\n",
        "procedure.\n",
        "\n",
        "# Phase I: Find the kitchen\n",
        "\n",
        "Explore the map until you locate the kitchen. Use compass commands\n",
        "`N`, `S`, `E`, and `W` to move around. There may be doors in your\n",
        "way. Use the command `OPEN <adjective> DOOR` to open them,\n",
        "substituting whatever adjective you see in the room description.\n",
        "\n",
        "When you explore, pay careful attention to any occurrence of \"north\",\n",
        "\"south\", \"east\", or \"west\" in a room description. These words always\n",
        "indicate room exits. Explore all exits until you've located\n",
        "everything you need.\n",
        "\n",
        "During this phase, make a note of any items you come across, but do\n",
        "not pick any of them up.\n",
        "\n",
        "# Phase II: Search for ingredients\n",
        "\n",
        "Once you find the kitchen, use the command `READ COOKBOOK`. The\n",
        "cookbook will contain a list of ingredients, and then a list of\n",
        "directions for preparation. Right now, just pay attention to the\n",
        "list of ingredients. Don't worry about preparation until Phase III.\n",
        "\n",
        "Next, use the command `I` to list your inventory. You may already be\n",
        "carrying some of the ingredients you need. If you are carrying\n",
        "anything that you *don't* need, use the `DROP` command to drop it.\n",
        "You may find some items in your inventory that you didn't pick up,\n",
        "which were there at the start of the game. This is normal.\n",
        "\n",
        "Third, use the command `OPEN FRIDGE`. If the fridge contains any\n",
        "ingredients you need, use the `GET` command to pick them up.\n",
        "\n",
        "Now, figure out what ingredients you are still missing, and then\n",
        "continue exploring the map until you find them.\n",
        "\n",
        "Pick up only the ingredients that the recipe calls for. Pay\n",
        "attention to their entire description. For example, if the recipe\n",
        "calls for a red pepper, don't pick up a yellow pepper unles the\n",
        "recipe needs that too.\n",
        "\n",
        "If you try to pick something up and the game tells you, \"You're\n",
        "carrying too many things already\", you've messed up: either you're\n",
        "carrying something you don't need, or you don't need the thing\n",
        "you're trying to pick up.  Check your inventory again (use `I`),\n",
        "compare your inventory against the recipe, and `DROP` any\n",
        "unnecessary items.\n",
        "\n",
        "If you get lost or stuck in a loop while exploring in Phase II,\n",
        "remember the principles from Phase I: look for \"north\", \"south\",\n",
        "\"east\", and \"west\" in room descriptions to make sure you haven't\n",
        "overlooked any exits. If you notice a closed door, that's certainly\n",
        "a way you haven't explored yet.\n",
        "\n",
        "# Phase III: Prepare your meal\n",
        "\n",
        "Once you have all your ingredients, return to the kitchen. Now\n",
        "`READ COOKBOOK` again, and then check your inventory again.\n",
        "Double-check that your inventory contains all the required\n",
        "ingredients and nothing else. If you made a mistake, return to\n",
        "phase II and correct it.\n",
        "\n",
        "Now you are ready to follow the directions in the cookbook. Each\n",
        "step except the last one in the list of directions is either a\n",
        "cutting step, or a cooking step. A cutting step calls for you either\n",
        "to *slice*, *dice*, or *chop* an ingredient. A cooking step calls\n",
        "for you either to *roast*, *fry*, or *grill* an ingredient.\n",
        "\n",
        "Determine if any steps involve cutting. If and only if you need to\n",
        "cut anything, use `GET KNIFE` to pick up the knife. You might have\n",
        "to drop something first to make room for the knife in your inventory.\n",
        "\n",
        "Now, follow the directions in order and follow them exactly. Use the\n",
        "following commands:\n",
        "\n",
        "* If the cookbook says to *slice* an ingredient, use `SLICE <ingredient> WITH KNIFE`.\n",
        "* If the cookbook says to *dice* an ingredient, use `DICE <ingredient> WITH KNIFE`.\n",
        "* If the cookbook says to *chop* an ingredient, use `CHOP <ingredient> WITH KNIFE`.\n",
        "* If the cookbook says to *roast* an ingredient, use `COOK <ingredient> WITH OVEN`.\n",
        "* If the cookbook says to *fry* an ingredient, use `COOK <ingredient> WITH STOVE`.\n",
        "* If the cookbook says to *grill* an ingredient, use `COOK <ingredient> WITH BBQ`.\n",
        "\n",
        "Be careful to use the right verb for cutting and the right appliance\n",
        "for cooking! If you slice something that you should have diced or\n",
        "chopped, or if you roast something that you should have fried or\n",
        "grilled, you'll lose the game. Also be sure not to cook any\n",
        "ingredient more than once, or you'll burn it.\n",
        "\n",
        "Everything you need for meal preparation is in the kitchen, except\n",
        "for the BBQ. The BBQ is in the backyard. So, if you have to grill\n",
        "something, you will have to go to the backyard first and then return\n",
        "to the kitchen afterward. After you get back to the kitchen, you\n",
        "should `READ COOKBOOK` again so you can remember where you left off.\n",
        "\n",
        "The final step in the list of directions will be \"prepare meal\", so\n",
        "once you have done everything else, use `PREPARE MEAL` to put the\n",
        "ingredients together; make sure you're still holding them all. You\n",
        "can drop the knife now if you need to. Finally, use the command\n",
        "`EAT MEAL` to win the game, and then `QUIT`.\"\"\""
      ],
      "metadata": {
        "id": "wEc9lYQEBGgY"
      },
      "id": "wEc9lYQEBGgY",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the developer prompt comes a walkthrough of sample game, generated based on what we specify in `SAMPLE_GAMES`. Each sample game either can be sourced from a URL, or can be generated from a `tw-make` command line and a seed. To demonstrate that we haven't cherry-picked anything here, we use the demo game from the TextWorld website. This game is missing a number of difficulty features that are enabled in our evaluation games, but it turns out to be good enough.\n",
        "\n",
        "The agent will see `INSTRUCTIONS` as a developer prompt, followed by this sample game as an assistant/user interaction, followed by repetition of the instructions."
      ],
      "metadata": {
        "id": "CK4yjFTvClCe"
      },
      "id": "CK4yjFTvClCe"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dd4df6e8-8ef2-45bd-894e-5ea92b641c00",
      "metadata": {
        "id": "dd4df6e8-8ef2-45bd-894e-5ea92b641c00"
      },
      "outputs": [],
      "source": [
        "from typing import List, Union, TypedDict, NotRequired\n",
        "\n",
        "UrlSampleGame = TypedDict('UrlSampleGame', {\n",
        "    'url': str,\n",
        "    'solution': List[str],\n",
        "})\n",
        "SeedSampleGame = TypedDict('SeedSampleGame', {\n",
        "    'tw_make_args': NotRequired[List[str]],\n",
        "    'seed': int,\n",
        "    'solution': List[str],\n",
        "})\n",
        "SampleGame = Union[UrlSampleGame, SeedSampleGame]\n",
        "\n",
        "SAMPLE_GAMES : List[SampleGame] = [\n",
        "    {\n",
        "        'url': (\n",
        "            \"https://textworldparchmentserver.z13.web.core.windows.net/games/game1.z8\"\n",
        "        ),\n",
        "        'solution': [\n",
        "            \"(I see exits to the south, east, and west. I'm in Phase I, searching for \"\n",
        "                \"the kitchen. I've started the game in the backyard, where the BBQ is. \"\n",
        "                \"That isn't important right now, but I'll remember it for later in \"\n",
        "                \"case I need to grill something. Let's try the east exit first.) E\",\n",
        "            \"(I see an exit to the west. Looks like this is a dead end with nothing \"\n",
        "                \"useful, so I'll go back west) W\",\n",
        "            \"(I see exits to the south, east, and west.  I'll search westward next, \"\n",
        "                \"but first I need to open the door in my way) OPEN WOODEN DOOR\",\n",
        "            \"(Now that the door is open, the path west is clear) W\",\n",
        "            \"(I see an exit to the east. Another dead end. The toolbox and workbench \"\n",
        "                \"aren't useful.) E\",\n",
        "            \"(I see exits to the south, east, and west.  I've checked east and west, \"\n",
        "                \"so only south remains. There's another door there I need to open.) \"\n",
        "                \"OPEN SCREEN DOOR\",\n",
        "            \"(Now my way south is clear.) S\",\n",
        "            \"(I see exits to the north, south, east, and west. I found the kitchen, \"\n",
        "                \"so I'm in Phase II now. The first thing to do in Phase II is read \"\n",
        "                \"the cookbook.) READ COOKBOOK\",\n",
        "            \"(Okay, I'm looking for a black papper, a chicken leg, and milk. Do I \"\n",
        "                \"already have any of that?) I\",\n",
        "            \"(No, there's nothing in my inventory. So there's nothing I need to drop, \"\n",
        "                \"but three ingredients to search for. The fridge is the first place \"\n",
        "                \"to search.) OPEN FRIDGE\",\n",
        "            \"(That raw chicken leg is one of my three ingredients, so I should pick \"\n",
        "                \"it up. The wing isn't an ingredient, so I'll ignore that.) \"\n",
        "                \"GET RAW CHICKEN LEG\",\n",
        "            \"(That's one ingredient down, two I'm still searching for. I see there \"\n",
        "                \"are exits from here in all four directions, but I've already explored \"\n",
        "                \"everything to the north. Let's try west.)  OPEN FROSTED-GLASS DOOR\",\n",
        "            \"(Now my path west is clear.) W\",\n",
        "            \"(I see an exit to the east. I don't need flour, so there's nothing useful \"\n",
        "                \"here, and it's a dead end.) E\",\n",
        "            \"(I see exits to the north, south, east, and west. The east and south \"\n",
        "                \"exits are still unexplored. Let's go east.) E\",\n",
        "            \"(I see exits to the south and west. There's nothing useful here, but \"\n",
        "                \"there's an unexplored exit to the south.) S\",\n",
        "            \"(I see exits to the north and west. Again nothing useful here, but \"\n",
        "                \"another unexplored exit to the west.) W\",\n",
        "            \"(I see exits to the north, east, and west. In my last three turns I went \"\n",
        "                \"east, south, and west from the kitchen, so that north exit probably \"\n",
        "                \"takes me back to the kitchen. West seems like the most promising \"\n",
        "                \"direction for further exploration, but I need to open the door \"\n",
        "                \"first.) OPEN FRONT DOOR\",\n",
        "            \"(Now my way west is clear.) W\",\n",
        "            \"(I see exits to the east and west. There's nothing useful here, but \"\n",
        "                \"there's an explored exit to the west.) W\",\n",
        "            \"(I see exits to the north and east. Again nothing useful here, but \"\n",
        "                \"there's a door to the north.) OPEN SLIDING DOOR\",\n",
        "            \"(Now my way north is clear.) N\",\n",
        "            \"(I see an exit to the south. Jackpot! This room has both of the \"\n",
        "                \"ingredients I'm still searching for. First, the black pepper.) \"\n",
        "                \"GET BLACK PEPPER\",\n",
        "            \"(I also need the milk.) GET MILK\",\n",
        "            \"(I don't need the red hot pepper or the salt. I have all my ingredients \"\n",
        "                \"now, which means I'm in Phase III and should return to the kitchen \"\n",
        "                \"by going back the way I came.) S\",\n",
        "            \"(I see exits to the north and east. The house is back east.) E\",\n",
        "            \"(I see exits to the east and west. I'll go east again to re-enter the \"\n",
        "                \"house.) E\",\n",
        "            \"(I see exits to the north, east, and west. Okay, now I'm back in this \"\n",
        "                \"corridor. I speculated earlier that north would be a shortcut back \"\n",
        "                \"to the kitchen.) N\",\n",
        "            \"(I see exits to the north, south, east, and west. I'm back in the \"\n",
        "                \"kitchen, so it's time to re-read the cookbook.) READ COOKBOOK\",\n",
        "            \"(Now I'll check my inventory to double-check that I have all the \"\n",
        "                \"ingredients.) I\",\n",
        "            \"(The ingredients I need are a black pepper, chicken leg, and milk. That \"\n",
        "                \"exactly matches my inventory, so that means I did everything right \"\n",
        "                \"so far and can proceed with the directions. Sice none of the \"\n",
        "                \"directions involve cutting, I can ignore the knife. The first \"\n",
        "                \"direction says to roast the chicken leg. When I need to roast \"\n",
        "                \"something, I use the oven. I mustn't use the stove or the BBQ; \"\n",
        "                \"I'd lose the game if I did that.)  COOK RAW CHICKEN LEG WITH OVEN\",\n",
        "            \"(Okay, checking my inventory one more time: I should still be holding \"\n",
        "                \"all the now-cooked ingredients.) I\",\n",
        "            \"(Right. I'm still holding the now-roasted chicken leg, as well as milk \"\n",
        "                \"and the black pepper which didn't need any preparation. Now, the \"\n",
        "                \"final step in the directions is to prepare the meal, and I should be \"\n",
        "                \"ready for that.) PREPARE MEAL\",\n",
        "            \"(Finally, I can eat the meal. This should win the game.) EAT MEAL\",\n",
        "        ],\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we get into our implementation proper. We'll start by developing two utility functions, respectively for cleaning up the game's output before the agent sees it, and cleaning up the agent's input before the game sees it. `clean_obs` removes some junk that the game tries to print into the status bar but ends up in the main output instead. `strip_parentheticals` removes the parenthesized chain-of-thought output that the agent is instructed to provide but which the game can't parse."
      ],
      "metadata": {
        "id": "U0tXDL04ERde"
      },
      "id": "U0tXDL04ERde"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_obs(obs : str) -> str:\n",
        "    \"\"\"Observations returned by the TextWorld gym include, without demarcation, things\n",
        "    that the Z machine meant to put into the status bar rather than the main text\n",
        "    window. This is ugly and unhelpful, so we use this function to strip it out by\n",
        "    removing everything after the last '>'.\"\"\"\n",
        "    return re.sub(r\">[^>]*$\", \"> \", obs)\n",
        "\n",
        "\n",
        "def strip_parentheticals(action : str) -> str:\n",
        "    \"\"\"The LLM is instructed to place its chain-of-thought in parentheses. This function\n",
        "    strips away parenthetical content so it doesn't get passed to the game parser.\"\"\"\n",
        "    # Strip balanced, innermost parentheticals until none remain\n",
        "    while True:\n",
        "        new_action = re.sub(r\"[(][^()]*[)]\", \"\", action)\n",
        "        if new_action == action:\n",
        "            break\n",
        "        action = new_action\n",
        "    # Strip to/from unbalanced parens\n",
        "    action = re.sub(r\"^.*[)]\", \"\", action)\n",
        "    action = re.sub(r\"[(].*$\", \"\", action)\n",
        "    return action.lstrip(\" \\r\\n\").strip(\" \\r\\n.\")"
      ],
      "metadata": {
        "id": "l-6jlqg3EJde"
      },
      "id": "l-6jlqg3EJde",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another utility function. `extend_messages` takes a transcript (i.e., a list of chat-completion chunks), a game environment, and some input from the agent, executes the input, and extends the transcript with both the input and the game's response to it."
      ],
      "metadata": {
        "id": "nEyLtEouHdYj"
      },
      "id": "nEyLtEouHdYj"
    },
    {
      "cell_type": "code",
      "source": [
        "import openai, sys, textworld.gym\n",
        "from typing import Any, Iterable, List, Optional, Tuple, TypedDict\n",
        "\n",
        "TranscriptChunk = TypedDict('TranscriptChunk', {'role': str, 'content': str})\n",
        "Transcript = List[TranscriptChunk]\n",
        "TranscriptIter = Iterable[TranscriptChunk]\n",
        "\n",
        "def extend_messages(\n",
        "        messages : Transcript,\n",
        "        action : str,\n",
        "        env : textworld.gym.envs.TextworldGymEnv,\n",
        "        render=False,\n",
        "        prestripped : Optional[str] = None\n",
        "    ) -> Tuple[float, bool, Any]:\n",
        "    \"\"\"Executes `action` in `env` and then extends `messages` the resulting\n",
        "    assistant/user exchange. If `render` is `True`, prints the exchange to stdout.\"\"\"\n",
        "    messages.append({\"role\": \"assistant\", \"content\": action})\n",
        "    if prestripped is None:\n",
        "        prestripped = strip_parentheticals(action)\n",
        "    if render:\n",
        "        print(\"> \" + action)\n",
        "    obs, score, done, infos = env.step(prestripped)\n",
        "    obs = clean_obs(obs)\n",
        "    if render:\n",
        "        print(obs, end=\"\")\n",
        "        sys.stdout.flush()\n",
        "    messages.append({\"role\": \"user\", \"content\": obs})\n",
        "    return (score, done, infos)"
      ],
      "metadata": {
        "id": "h6dokSOqFVbr"
      },
      "id": "h6dokSOqFVbr",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `make_game` function takes care of invoking `tw-make` to generate a game. It stores games in `WORK_DIR/games` and names them according to a hash of the command line and the seed that was used. This provides for memoization: if the file already exists, then the game has already been generated and the function can return early."
      ],
      "metadata": {
        "id": "RDmsBBfbIMvG"
      },
      "id": "RDmsBBfbIMvG"
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib, random, os, os.path, subprocess\n",
        "from typing import List, Optional\n",
        "\n",
        "def game_hash(tw_make_args : List[str]) -> str:\n",
        "    \"\"\"Returns a hash of the arguments to `tw_make`, as a hex digest\"\"\"\n",
        "    return hashlib.sha256(\" \".join(tw_make_args).encode(\"utf-8\")).hexdigest()\n",
        "\n",
        "def make_game(seed : Optional[int] = None, tw_make_args : Optional[List[str]] = None) -> str:\n",
        "    \"\"\"Invokes 'tw-make' with `tw_make_args` (defaulting to `TW_MAKE_ARGS`) and an\n",
        "    additional '--seed' argument of `seed` (default random). Stores the result in a\n",
        "    file named based on the seed and a hash of `tw_make_args`, and returns that\n",
        "    filename. If the file already exists, returns it immediately without\n",
        "    regenerating.\"\"\"\n",
        "    if seed is None:\n",
        "        seed = random.randint(1, 65535)\n",
        "    if tw_make_args is None:\n",
        "        tw_make_args = TW_MAKE_ARGS\n",
        "\n",
        "    game_dir = os.path.join(WORK_DIR, \"games\")\n",
        "    game_file = \"{}-{}.z8\".format(\n",
        "        game_hash(tw_make_args), seed\n",
        "    )\n",
        "    os.makedirs(game_dir, exist_ok=True)\n",
        "    out = os.path.join(game_dir, game_file)\n",
        "    if os.path.exists(out):\n",
        "        return out\n",
        "    args = [TW_MAKE_BIN] + tw_make_args + [\"--output\", out, \"--seed\", str(seed)]\n",
        "    subprocess.run(args).check_returncode()\n",
        "    return out"
      ],
      "metadata": {
        "id": "OSkl_AwSJaWb"
      },
      "id": "OSkl_AwSJaWb",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`make_prompt` builds the prompt by interpreting what we've specified in `INSTRUCTIONS` and `SAMPLE_GAMES`."
      ],
      "metadata": {
        "id": "eGtUPfXNKkuf"
      },
      "id": "eGtUPfXNKkuf"
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, tempfile, urllib, textworld.gym\n",
        "from typing import List\n",
        "\n",
        "def make_prompt(instructions : str, sample_games: List[SampleGame]) -> Transcript:\n",
        "    \"\"\"Runs the sample games to produce transcripts, then combines those with the\n",
        "    instructions to produce a complete prompt.\"\"\"\n",
        "\n",
        "    prompt : List[TranscriptChunk] = [{\"role\": \"developer\", \"content\": instructions}]\n",
        "\n",
        "    for game in sample_games:\n",
        "        if 'url' in game:\n",
        "            with urllib.request.urlopen(game['url']) as response:\n",
        "                with tempfile.NamedTemporaryFile(suffix=\".z8\") as tmp_file:\n",
        "                    shutil.copyfileobj(response, tmp_file)\n",
        "                    env_id = textworld.gym.register_game(\n",
        "                        tmp_file.name,\n",
        "                        name='tmp_file.name'\n",
        "                    )\n",
        "                    env = textworld.gym.make(env_id)\n",
        "                    obs, _ = env.reset()\n",
        "                    prompt += [{\"role\": \"user\", \"content\": clean_obs(obs)}]\n",
        "                    for step in game[\"solution\"]:\n",
        "                        extend_messages(prompt, step, env)\n",
        "        elif 'seed' in game:\n",
        "            path = make_game(game['seed'], game.get('tw_make_args', TW_MAKE_ARGS))\n",
        "            env_id = textworld.gym.register_game(path, name=path)\n",
        "            env = textworld.gym.make(env_id)\n",
        "            obs, _ = env.reset()\n",
        "            prompt += [{\"role\": \"user\", \"content\": clean_obs(obs)}]\n",
        "            for step in game[\"solution\"]:\n",
        "                extend_messages(prompt, step, env)\n",
        "        else:\n",
        "            raise ValueError(\"Each sample game must contain either a url or a seed\")\n",
        "\n",
        "        prompt += [\n",
        "            {\"role\": \"assistant\", \"content\": \"QUIT\"},\n",
        "            {\n",
        "                \"role\": \"developer\",\n",
        "                \"content\": (\n",
        "                    \"Well done! Now play a new game. Your instructions are the \"\n",
        "                    \"same as before:\\n\\n\" + instructions\n",
        "                ),\n",
        "            },\n",
        "        ]\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "25iEzwVvJ9il"
      },
      "id": "25iEzwVvJ9il",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`make_prompt` includes a developer prompt, but not all models support it. This next function will replace it with something else when needed."
      ],
      "metadata": {
        "id": "BFjjE6LqMQlO"
      },
      "id": "BFjjE6LqMQlO"
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_dev_prompt(\n",
        "        prompt : Transcript,\n",
        "        replacement : str = \"user\"\n",
        "    ) -> TranscriptIter:\n",
        "    \"\"\"Iterates over `prompt` and replaces every instance of the developer role with\n",
        "    the `replacement` role.\"\"\"\n",
        "    for item in prompt:\n",
        "        if item['role'] == \"developer\":\n",
        "            newitem = dict(item)\n",
        "            newitem['role'] = replacement\n",
        "            yield newitem\n",
        "        else:\n",
        "            yield item"
      ],
      "metadata": {
        "id": "kjoe4GQ7LphL"
      },
      "id": "kjoe4GQ7LphL",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This type definition specifies how the result of a game is represented. `model`, `tw_make_args`, and `seed` are known at the start of the game and indicate what model was playing the game and what game it was playing. `messages` is the complete game transcript. `outcome` specifies how the game ended: whether it was won, lost, ended due to hitting the turn limit, ended due to repeated silence from the agent, ended due to the agent quitting out of the game, or ended due to an API error."
      ],
      "metadata": {
        "id": "3XevrznjPvCr"
      },
      "id": "3XevrznjPvCr"
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, List, Optional, Literal\n",
        "GameResult = TypedDict('GameResult', {\n",
        "    'model': str,\n",
        "    'tw_make_args': List[str],\n",
        "    'seed': int,\n",
        "    'error': Optional[str],\n",
        "    'outcome': Literal['won', 'lost', 'turnmax', 'silence', 'quit', 'error'],\n",
        "    'messages': Transcript,\n",
        "    'turns': int,\n",
        "})"
      ],
      "metadata": {
        "id": "3CI4cGP9Ni7i"
      },
      "id": "3CI4cGP9Ni7i",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're finally ready to define our `play_game` function which interfaces the agent to the game, producing a `GameResult`."
      ],
      "metadata": {
        "id": "VFkSSN-TQx9A"
      },
      "id": "VFkSSN-TQx9A"
    },
    {
      "cell_type": "code",
      "source": [
        "import textworld, textworld.gym, openai, re, sys, time\n",
        "from typing import Optional, List\n",
        "\n",
        "MEMO_INSTRUCTIONS : Optional[str] = None\n",
        "MEMO_SAMPLE_GAMES : Optional[List[SampleGame]] = None\n",
        "DEFAULT_PROMPT : Optional[Transcript] = None\n",
        "\n",
        "def play_game(\n",
        "        seed : int,\n",
        "        model : str,\n",
        "        tw_make_args : Optional[List[str]] = None,\n",
        "        prompt : Optional[Transcript ] = None,\n",
        "        max_turns : Optional[int] = None,\n",
        "        render : bool = False\n",
        "    ) -> GameResult:\n",
        "    global MEMO_INSTRUCTIONS, MEMO_SAMPLE_GAMES, DEFAULT_PROMPT\n",
        "    if MEMO_INSTRUCTIONS != INSTRUCTIONS or MEMO_SAMPLE_GAMES != SAMPLE_GAMES:\n",
        "        DEFAULT_PROMPT = make_prompt(INSTRUCTIONS, SAMPLE_GAMES)\n",
        "        MEMO_INSTRUCTIONS = str(INSTRUCTIONS)\n",
        "        MEMO_SAMPLE_GAMES = list(SAMPLE_GAMES)\n",
        "    if prompt is None:\n",
        "        prompt = DEFAULT_PROMPT\n",
        "    if max_turns is None:\n",
        "        max_turns = MAX_TURNS\n",
        "    if tw_make_args is None:\n",
        "        tw_make_args = TW_MAKE_ARGS\n",
        "\n",
        "    path = make_game(seed, tw_make_args)\n",
        "\n",
        "    request_infos = textworld.core.EnvInfos(lost=True, won=True)\n",
        "    env_id = textworld.gym.register_game(\n",
        "        path, request_infos=request_infos, max_episode_steps=max_turns,\n",
        "        name=path\n",
        "    )\n",
        "\n",
        "    status = {\n",
        "        'model': model,\n",
        "        'tw_make_args': tw_make_args,\n",
        "        'seed': seed,\n",
        "        'error': None,\n",
        "    }\n",
        "\n",
        "    game_env = textworld.gym.make(env_id)\n",
        "    obs, infos = game_env.reset()\n",
        "    obs = clean_obs(obs)\n",
        "    done = False\n",
        "    turns = 0\n",
        "    silences = 0\n",
        "\n",
        "    if render:\n",
        "        print(obs, end=\"\")\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    model_args = dict(MODELS[model])\n",
        "    client_args = dict(CLIENTS[model_args[\"client\"]])\n",
        "    del model_args[\"client\"]\n",
        "    if \"developer_role\" in model_args:\n",
        "        developer_role = model_args[\"developer_role\"]\n",
        "        prompt = list(replace_dev_prompt(prompt, developer_role))\n",
        "        del model_args[\"developer_role\"]\n",
        "    else:\n",
        "        developer_role = \"developer\"\n",
        "    if \"model\" not in model_args:\n",
        "        model_args[\"model\"] = model\n",
        "\n",
        "    messages : Transcript = prompt + [{\"role\": \"user\", \"content\": obs}]\n",
        "\n",
        "    client = openai.OpenAI(**client_args)\n",
        "    while not done:\n",
        "        turns += 1\n",
        "        status['turns'] = turns\n",
        "        backoff = 30.0\n",
        "        consecutive_failures = 0\n",
        "        while True:\n",
        "            try:\n",
        "                model_args[\"messages\"] = messages\n",
        "                action = (\n",
        "                    client.chat.completions.create(**model_args)\n",
        "                    .choices[0]\n",
        "                    .message.content\n",
        "                )\n",
        "                break\n",
        "            except openai.RateLimitError:\n",
        "                time.sleep(backoff)\n",
        "                backoff *= 2.0\n",
        "            except openai.APIError as e:\n",
        "                if render:\n",
        "                    print(e)\n",
        "                consecutive_failures += 1\n",
        "                time.sleep(backoff)\n",
        "                backoff *= 2.0\n",
        "                if consecutive_failures > 3:\n",
        "                    status['outcome'] = 'error'\n",
        "                    status['error'] = str(e)\n",
        "                    status['messages'] = messages\n",
        "                    return status\n",
        "\n",
        "        stripped = strip_parentheticals(action)\n",
        "        if re.match(r\"QUIT\\b\", stripped, re.I):\n",
        "            messages += [{\"role\": \"assistant\", \"content\": action}]\n",
        "            if render:\n",
        "                print(\"> \" + action)\n",
        "\n",
        "            status['outcome'] = 'quit'\n",
        "            status['messages'] = messages\n",
        "            return status\n",
        "        elif '.' in stripped or ',' in stripped or ';' in stripped or \\\n",
        "                '\\n' in stripped or re.search(r\"\\bthen\\b\", stripped, re.I):\n",
        "            silences += 1\n",
        "            correction = [\n",
        "                {\"role\": \"assistant\", \"content\": action},\n",
        "                {\n",
        "                    \"role\": developer_role,\n",
        "                    \"content\": (\n",
        "                        \"Your last message looks like you may have tried to issue \"\n",
        "                        \"multiple commands at once. The game doesn't support this. \"\n",
        "                        \"Try again, one command at a time.\\n\\n> \"\n",
        "                    ),\n",
        "                },\n",
        "            ]\n",
        "            if render:\n",
        "                print(\"> \" + correction[0]['content'])\n",
        "                print(correction[1]['content'], end='')\n",
        "            messages += correction\n",
        "            if silences >= 3:\n",
        "                status['outcome'] = 'silence'\n",
        "                status['messages'] = messages\n",
        "                return status\n",
        "        elif stripped == \"\":\n",
        "            silences += 1\n",
        "            correction = [\n",
        "                {\"role\": \"assistant\", \"content\": action},\n",
        "                {\n",
        "                    \"role\": developer_role,\n",
        "                    \"content\": (\n",
        "                        \"Your last message contained nothing except a parenthetical, \"\n",
        "                        \"so it couldn't be provided to the game. Try again. If you've \"\n",
        "                        \"completely given up, just say QUIT.\\n\\n> \"\n",
        "                    ),\n",
        "                },\n",
        "            ]\n",
        "\n",
        "            if render:\n",
        "                print(\"> \" + correction[0]['content'])\n",
        "                print(correction[1]['content'], end='')\n",
        "            messages += correction\n",
        "            if silences >= 3:\n",
        "                status['outcome'] = 'silence'\n",
        "                status['messages'] = messages\n",
        "                return status\n",
        "        else:\n",
        "            silences = 0\n",
        "            try:\n",
        "                _, done, infos = extend_messages(\n",
        "                    messages, action, game_env, render, prestripped=stripped\n",
        "                )\n",
        "            except Exception as e:\n",
        "                status['outcome'] = 'error'\n",
        "                status['messages'] = messages\n",
        "                status['error'] = str(e)\n",
        "                return status\n",
        "\n",
        "    if infos['lost']:\n",
        "        status['outcome'] = 'lost'\n",
        "    elif infos['won']:\n",
        "        status['outcome'] = 'won'\n",
        "    else:\n",
        "        status['outcome'] = 'turnmax'\n",
        "    status['messages'] = messages\n",
        "    return status"
      ],
      "metadata": {
        "id": "DIiYMFxYRbeC"
      },
      "id": "DIiYMFxYRbeC",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we set up some machinery to run games in parallel batches and let the agent retry up to a fixed number of attempts if it doesn't win the first time. `run_experiment` will return a list of lists of `GameResults`, where each inner list is a series of attempts at the same game seed. Results are stored, and any model/seed/tw_make_args\n",
        "combination that has already been run will have the stored result returned rather than being re-run."
      ],
      "metadata": {
        "id": "hgpaT7gaibeH"
      },
      "id": "hgpaT7gaibeH"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5703e2bb-053f-454a-9fe9-db9cc68555a6",
      "metadata": {
        "id": "5703e2bb-053f-454a-9fe9-db9cc68555a6"
      },
      "outputs": [],
      "source": [
        "import json, multiprocessing, os, os.path\n",
        "from typing import List\n",
        "\n",
        "def experiment_worker(\n",
        "        seed : int,\n",
        "        model : str,\n",
        "        max_attempts : int,\n",
        "        tw_make_args : List[str],\n",
        "        prompt : Transcript,\n",
        "        max_turns : int,\n",
        "        out_dir : str\n",
        "    ) -> List[GameResult]:\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    results = list()\n",
        "    nonerror_attempts = 0\n",
        "    for attempt in range(5*max_attempts):\n",
        "        if nonerror_attempts >= max_attempts:\n",
        "            break\n",
        "        out_path = os.path.join(out_dir, str(attempt) + \".json\")\n",
        "        try:\n",
        "            with open(out_path, 'r') as f:\n",
        "                saved_result = json.load(f)\n",
        "                results.append(saved_result)\n",
        "                if saved_result['outcome'] == 'won':\n",
        "                    return results\n",
        "                elif saved_result['outcome'] != 'error':\n",
        "                    nonerror_attempts += 1\n",
        "                continue\n",
        "        except:\n",
        "            pass\n",
        "        result = play_game(seed, model,\n",
        "                           tw_make_args=tw_make_args,\n",
        "                           prompt=prompt,\n",
        "                           max_turns=max_turns)\n",
        "        results.append(result)\n",
        "        with open(out_path, 'w') as f:\n",
        "            json.dump(result, f, indent=4, sort_keys=True)\n",
        "        if result['outcome'] == 'won':\n",
        "            return results\n",
        "        elif result['outcome'] != 'error':\n",
        "            nonerror_attempts += 1\n",
        "    return results\n",
        "\n",
        "def pregenerate_games(\n",
        "        start_seed : int = 1,\n",
        "        n_games : int = 100,\n",
        "        tw_make_args : Optional[List[str]] = None\n",
        "    ):\n",
        "    with multiprocessing.Pool() as p:\n",
        "        p.starmap(\n",
        "            make_game,\n",
        "            [\n",
        "                (seed, tw_make_args)\n",
        "                for seed in range(start_seed, start_seed + n_games)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "def run_experiment(\n",
        "        models : List[str],\n",
        "        experiment_name : str = 'experiment',\n",
        "        processes : int = 1,\n",
        "        start_seed : int = 1,\n",
        "        n_games : int = 100,\n",
        "        max_attempts : int = 3,\n",
        "        tw_make_args : Optional[List[str]] = None,\n",
        "        prompt : Optional[Transcript] = None,\n",
        "        max_turns : Optional[int] = None,\n",
        ") -> List[List[GameResult]]:\n",
        "    if tw_make_args is None:\n",
        "        tw_make_args = TW_MAKE_ARGS\n",
        "    if prompt is None:\n",
        "        prompt = DEFAULT_PROMPT\n",
        "    if max_turns is None:\n",
        "        max_turns = MAX_TURNS\n",
        "\n",
        "    pregenerate_games(start_seed, n_games, tw_make_args)\n",
        "\n",
        "    worker_arguments = [\n",
        "        (\n",
        "            seed,\n",
        "            model,\n",
        "            max_attempts,\n",
        "            tw_make_args,\n",
        "            prompt,\n",
        "            max_turns,\n",
        "            os.path.join(\n",
        "                WORK_DIR,\n",
        "                experiment_name,\n",
        "                game_hash(tw_make_args),\n",
        "                model,\n",
        "                str(seed)\n",
        "            )\n",
        "        )\n",
        "        for model in models\n",
        "        for seed in range(start_seed, start_seed + n_games)\n",
        "    ]\n",
        "\n",
        "    with multiprocessing.Pool(processes) as p:\n",
        "        return p.starmap(experiment_worker, worker_arguments)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One last utility function to make it convenient to download experimental results."
      ],
      "metadata": {
        "id": "hghuvotii6IB"
      },
      "id": "hghuvotii6IB"
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path, tarfile, tempfile\n",
        "def download_experiment(experiment: str = 'experiment'):\n",
        "    try:\n",
        "        from google.colab import files\n",
        "    except ImportError as e:\n",
        "        raise RuntimeError(\n",
        "            \"Download failed: this notebook is not running in Google Colab.\"\n",
        "        ) from e\n",
        "        return\n",
        "\n",
        "    experiment_dir = os.path.join(WORK_DIR, experiment)\n",
        "    if not os.path.exists(experiment_dir):\n",
        "        raise FileNotFoundError(\n",
        "            f\"Download failed: experiment directory '{experiment_dir}' not found.\"\n",
        "        )\n",
        "\n",
        "    with tempfile.TemporaryDirectory() as temp_dir:\n",
        "        tar_filename = os.path.join(temp_dir, f\"{experiment}.tar.gz\")\n",
        "        with tarfile.open(tar_filename, \"w:gz\") as tar:\n",
        "            tar.add(experiment_dir, arcname=os.path.basename(experiment_dir))\n",
        "\n",
        "        files.download(tar_filename)"
      ],
      "metadata": {
        "id": "kPlaW84XVnfy"
      },
      "id": "kPlaW84XVnfy",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we're ready to run! `processes=12` is about right for running close to the rate limit on my Tier 4 OpenAI account."
      ],
      "metadata": {
        "id": "7vxGc1WrjFsx"
      },
      "id": "7vxGc1WrjFsx"
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_ATTEMPTS = 3\n",
        "ALL_RESULTS = run_experiment(\n",
        "    ['gpt-4o', 'gpt-4o-mini', 'llama3.1-405b-instruct-fp8', 'llama3.3-70b-instruct-fp8'],\n",
        "    processes=12,\n",
        "    n_games=100,\n",
        "    max_attempts=MAX_ATTEMPTS\n",
        ")"
      ],
      "metadata": {
        "id": "yyuW95F2OiUE"
      },
      "id": "yyuW95F2OiUE",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis"
      ],
      "metadata": {
        "id": "KmcOh3f8yOcQ"
      },
      "id": "KmcOh3f8yOcQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll build a table of cumulative outcome frequencies over each attempt."
      ],
      "metadata": {
        "id": "kZoeH0-T_v9h"
      },
      "id": "kZoeH0-T_v9h"
    },
    {
      "cell_type": "code",
      "source": [
        "FILTERED_RESULTS = []\n",
        "for result_list in ALL_RESULTS:\n",
        "    filtered = [ result for result in result_list if result['outcome'] != 'error']\n",
        "    FILTERED_RESULTS.append(filtered)\n",
        "\n",
        "RESULTS_BY_MODEL : Dict[str, List[List[GameResult]]] = dict()\n",
        "for results in FILTERED_RESULTS:\n",
        "    model = results[0]['model']\n",
        "    if model not in RESULTS_BY_MODEL:\n",
        "        RESULTS_BY_MODEL[model] = list()\n",
        "    RESULTS_BY_MODEL[model].append(results)\n",
        "\n",
        "OUTCOMES : Dict[str, List[Dict[str, int]]] = dict()\n",
        "CUMULATIVE_OUTCOMES : Dict[str, List[Dict[str, int]]] = dict()\n",
        "\n",
        "for model, all_model_results in RESULTS_BY_MODEL.items():\n",
        "    model_outcomes = [dict() for _ in range(MAX_ATTEMPTS)]\n",
        "    cumulative_model_outcomes = [None for _ in range(MAX_ATTEMPTS)]\n",
        "    cumulative_model_outcomes[0] = dict()\n",
        "    for attempt in range(MAX_ATTEMPTS):\n",
        "        for results in all_model_results:\n",
        "            if attempt < len(results):\n",
        "                outcome = results[attempt]['outcome']\n",
        "                if outcome not in model_outcomes[attempt]:\n",
        "                    model_outcomes[attempt][outcome] = 0\n",
        "                if outcome not in cumulative_model_outcomes[attempt]:\n",
        "                    cumulative_model_outcomes[attempt][outcome] = 0\n",
        "                model_outcomes[attempt][outcome] += 1\n",
        "                cumulative_model_outcomes[attempt][outcome] += 1\n",
        "            if attempt + 1 < MAX_ATTEMPTS:\n",
        "                cumulative_model_outcomes[attempt + 1] = \\\n",
        "                    dict(cumulative_model_outcomes[attempt])\n",
        "    OUTCOMES[model] = model_outcomes\n",
        "    CUMULATIVE_OUTCOMES[model] = cumulative_model_outcomes\n",
        "\n",
        "CUMULATIVE_OUTCOMES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH1eepWbp56u",
        "outputId": "6b119096-7f52-457d-c261-682934ee1810"
      },
      "id": "PH1eepWbp56u",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gpt-4o': [{'won': 89, 'lost': 4, 'quit': 7},\n",
              "  {'won': 98, 'lost': 4, 'quit': 9},\n",
              "  {'won': 100, 'lost': 4, 'quit': 9}],\n",
              " 'gpt-4o-mini': [{'won': 23,\n",
              "   'lost': 13,\n",
              "   'turnmax': 46,\n",
              "   'silence': 10,\n",
              "   'quit': 8},\n",
              "  {'won': 30, 'lost': 20, 'turnmax': 91, 'silence': 16, 'quit': 20},\n",
              "  {'won': 35, 'lost': 34, 'turnmax': 132, 'silence': 20, 'quit': 26}],\n",
              " 'llama3.1-405b-instruct-fp8': [{'won': 89,\n",
              "   'quit': 8,\n",
              "   'turnmax': 2,\n",
              "   'silence': 1},\n",
              "  {'won': 100, 'quit': 8, 'turnmax': 2, 'silence': 1},\n",
              "  {'won': 100, 'quit': 8, 'turnmax': 2, 'silence': 1}],\n",
              " 'llama3.3-70b-instruct-fp8': [{'quit': 19,\n",
              "   'won': 57,\n",
              "   'turnmax': 18,\n",
              "   'lost': 5,\n",
              "   'silence': 1},\n",
              "  {'quit': 24, 'won': 80, 'turnmax': 28, 'lost': 9, 'silence': 2},\n",
              "  {'quit': 30, 'won': 85, 'turnmax': 36, 'lost': 10, 'silence': 2}]}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Llama3.1-405B-Instruct-FP8 won 89/100 games on its first attempt and the rest on its second attempt. Nice!\n",
        "\n",
        "Now we're going to compute Bayesian credible intervals on these win rates. Consider each\n",
        "game as a biased coin independently drawn from some population. Each coin in the population has a different bias, and the distribution of biases is unknown. We toss each coin either `MAX_ATTEMPTS` times or until it comes up heads, whichever comes first. We want to compute a credible interval on the probability that a newly-drawn coin from this population will come up heads by its n'th toss for each n in [1..MAX_ATTEMPTS].\n",
        "\n",
        "Computing this for $n=1$ is straightforward: we can just compute the inverse CDF for a beta distribution with (e.g. for 89 wins) $\\alpha = 89.5,\\ \\beta = 11.5$ at (e.g. for a 95% confidence interval) 0.025 and 0.975. However, for $n>1$ it gets a lot messier and we're best off resorting to a Monte Carlo method. At each stage we draw beta random variates from the posterior distribution reached by having passed the previous stages."
      ],
      "metadata": {
        "id": "dcIq7EoYADdb"
      },
      "id": "dcIq7EoYADdb"
    },
    {
      "cell_type": "code",
      "source": [
        "# If you don't already have numpy and scipy installed, add them to\n",
        "# the pip install line at the very top of this notebook.\n",
        "import numpy as np\n",
        "from scipy.stats import beta\n",
        "\n",
        "def compute_credible_intervals(\n",
        "        N, ns,\n",
        "        prior_a=0.5,\n",
        "        prior_b=0.5,\n",
        "        conf_level=0.95,\n",
        "        nsamples=1000000\n",
        "):\n",
        "    intervals = []\n",
        "    # cumulative probability so far; initially, no chance of head.\n",
        "    cumulative = np.zeros(nsamples)\n",
        "    # Number of coins that reach the current stage\n",
        "    remaining = N\n",
        "    lower_percentile = (1 - conf_level) / 2.0 * 100\n",
        "    upper_percentile = (1 + conf_level) / 2.0 * 100\n",
        "\n",
        "    for n in ns:\n",
        "        # At each stage, we have 'remaining' coins available.\n",
        "        # Our Beta posterior parameters are:\n",
        "        a = n + prior_a\n",
        "        b = (remaining - n) + prior_b\n",
        "        # Draw samples for the probability of head at this stage.\n",
        "        p_samples = beta.rvs(a, b, size=nsamples)\n",
        "        # Update the cumulative probability.\n",
        "        # A coin gets head by this stage either if it already got head before,\n",
        "        # or, if not, it gets head in this stage.\n",
        "        cumulative += (1 - cumulative) * p_samples\n",
        "        # Compute the credible interval from the samples.\n",
        "        ci = np.percentile(cumulative, [lower_percentile, upper_percentile])\n",
        "        intervals.append(ci)\n",
        "        # Update the remaining coins for the next stage.\n",
        "        remaining -= n\n",
        "\n",
        "    return intervals"
      ],
      "metadata": {
        "id": "EXv7jYuxr8kZ"
      },
      "id": "EXv7jYuxr8kZ",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Tuple\n",
        "WIN_RATE_CREDIBLE_INTERVALS : Dict[str, List[Tuple[float, float]]] = dict()\n",
        "\n",
        "for model, outcome_dicts in OUTCOMES.items():\n",
        "    wins = [ outcome_dict.get('won', 0) for outcome_dict in outcome_dicts ]\n",
        "    cis = compute_credible_intervals(len(RESULTS_BY_MODEL[model]), wins)\n",
        "    WIN_RATE_CREDIBLE_INTERVALS[model] = [ (ci[0], ci[1]) for ci in cis ]\n",
        "\n",
        "WIN_RATE_CREDIBLE_INTERVALS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXtb-BnqHeBJ",
        "outputId": "9fa76a31-adb1-4ecb-f5b4-0d93c946cca2"
      },
      "id": "uXtb-BnqHeBJ",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gpt-4o': [(0.8175083884197585, 0.940097598387077),\n",
              "  (0.9397861454121765, 0.9960414688750009),\n",
              "  (0.9795307423009577, 0.9999963657003693)],\n",
              " 'gpt-4o-mini': [(0.15593107754352875, 0.31925219958167633),\n",
              "  (0.22089395764801617, 0.399218937102621),\n",
              "  (0.2701572993858289, 0.4556640786012336)],\n",
              " 'llama3.1-405b-instruct-fp8': [(0.817651980052568, 0.9400877173788655),\n",
              "  (0.9763106420616923, 0.9999952779039336),\n",
              "  (0.9848036098758056, 0.9999997362772812)],\n",
              " 'llama3.3-70b-instruct-fp8': [(0.47209598901986566, 0.6641005885884872),\n",
              "  (0.7167100851648446, 0.8709264424212316),\n",
              "  (0.7774182475862635, 0.913407572566829)]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FwzgHlfNer6K"
      },
      "id": "FwzgHlfNer6K",
      "execution_count": 21,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "r_IgLxj7uoHw"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}